{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bb9bc82",
   "metadata": {},
   "source": [
    "# K-Means Clustering and PCA Analysis of Intrusion Detection Network Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73700c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----This code performs clustering and classification of attack types using K-Means and PCA on KDD Cup 1999 dataset----------------\n",
    "\n",
    "# To start \n",
    "!pip install feature_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5821f76b",
   "metadata": {},
   "source": [
    "# Importing Essential Libraries for Advanced Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47186353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from feature_engine.selection import DropDuplicateFeatures\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from IPython.display import display  # Used for displaying dataframes and other outputs\n",
    "import pandas as pd  # Data manipulation and analysis\n",
    "from tensorflow.keras.utils import get_file  # Utilities for Keras, such as downloading files\n",
    "from sklearn import metrics  # Machine learning evaluation metrics\n",
    "from scipy.stats import zscore \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342b4b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = r\"C:\\home\\data\\kddcup99_csv.csv\"\n",
    "\n",
    "# Read the CSV file using the relative path\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08ef229",
   "metadata": {},
   "source": [
    "# Exploring Target Labels and Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb75ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------check target----------------\n",
    "df[\"label\"].unique()\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "try:\n",
    "      path = get_file('kddcup99_csv.csv', origin='file:///C:/home/data/kddcup99_csv.csv')\n",
    "except:\n",
    "    print('Error downloading')\n",
    "    raise\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "print('='*40)\n",
    "print('The number of data points are:', df.shape[0])\n",
    "print('='*40)\n",
    "print('The number of features are:', df.shape[1])\n",
    "print('='*40)\n",
    "output = df['label'].values\n",
    "labels = set(output)\n",
    "print('The different type of output labels are:', labels)\n",
    "print('='*125)\n",
    "print('The number of different output labels are:', len(labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163e6524",
   "metadata": {},
   "source": [
    "# Identifying Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f7c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_rows = df[df.duplicated()]\n",
    "print(\"Number of duplicate rows:\", len(duplicate_rows))\n",
    "print(\"Duplicate rows:\")\n",
    "print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a45274",
   "metadata": {},
   "source": [
    "# Clean Data and Remove nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2874d898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------Data Cleaning----------------------------------\n",
    "\n",
    "print('Null values in dataset are',len(df[df.isnull().any(1)]))\n",
    "print('='*40)\n",
    "\n",
    "# Checking for NULL values\n",
    "print('Null values in dataset are',len(df[df.isnull().any(1)]))\n",
    "print('='*40)\n",
    "\n",
    "\n",
    "# Checkng for DUPLICATE values\n",
    "df.drop_duplicates(keep='first', inplace = True)\n",
    "\n",
    "# For now, just drop NA's (rows with missing values)\n",
    "df.dropna(inplace=True,axis=1) \n",
    "\n",
    "#stored the data into a pickle file so we can load through\n",
    "df.to_pickle('df.pkl')\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "\n",
    "# Print the entire dataset after removing rows with NULL values\n",
    "print(df.head())\n",
    "\n",
    "# Print the entire dataset after removing rows with NULL values\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6653e853",
   "metadata": {},
   "source": [
    "# Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d764fc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Removing duplicate rows from the DataFrame\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Display the DataFrame 'df' after removing duplicates\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21189a8",
   "metadata": {},
   "source": [
    "# Quantifying Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd79030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of data points\n",
    "num_data_points = df.shape[0]\n",
    "print(\"Number of data points:\", num_data_points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57923621",
   "metadata": {},
   "source": [
    "# Attack Type distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31e23b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate class distribution\n",
    "class_distribution = df['label'].value_counts()\n",
    "\n",
    "unique_classes = df['label'].unique()\n",
    "print(\"Unique classes:\", unique_classes)\n",
    "\n",
    "sorted_yi = np.argsort(-class_distribution.values)\n",
    "for i in sorted_yi:\n",
    "    print('Number of data points in class', class_distribution.index[i],':', class_distribution.values[i], \n",
    "          '(', np.round((class_distribution.values[i] / df.shape[0] * 100), 3), '%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ecef47",
   "metadata": {},
   "source": [
    "# Identify Unique class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5429dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = df['label'].unique()\n",
    "print(\"Unique classes:\", unique_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca8cea9",
   "metadata": {},
   "source": [
    "# Distribution Bar Chart Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6273035e-7472-4cd4-ad97-c474fa828cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract the class distribution\n",
    "class_distribution = df['label'].value_counts()\n",
    "\n",
    "# Plot the class distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=df, x='label', order=class_distribution.index)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33e3a70",
   "metadata": {},
   "source": [
    "# Distribution of Percentage Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ef3439",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_yi = np.argsort(-class_distribution.values)\n",
    "for i in sorted_yi:\n",
    "    print('Number of data points in class', class_distribution.index[i],':', class_distribution.values[i], \n",
    "          '(', np.round((class_distribution.values[i]/df.shape[0]*100), 3), '%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0f2fc5",
   "metadata": {},
   "source": [
    "# Attack Distribution Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56506097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------attck distribution-------------------------\n",
    "class_distribution = df['label'].value_counts()\n",
    "sorted_yi = class_distribution.index\n",
    "\n",
    "#Calculating percentages\n",
    "percentages = np.round((class_distribution / df.shape[0] * 100), 3)\n",
    "\n",
    "# Create a DataFrame for the table\n",
    "table_data = pd.DataFrame({'Class': sorted_yi, 'Count': class_distribution, 'Percentage': percentages})\n",
    "\n",
    "#Display the table\n",
    "table_data = table_data.sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "table_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ca7000",
   "metadata": {},
   "source": [
    "# Descriptive Statistics: Z-Score Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9de774",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze(df):\n",
    "    # calculating z-scores for numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=[np.number])\n",
    "    z_scores = numeric_cols.apply(zscore)\n",
    "\n",
    "    # Create a DataFrame for the analysis results\n",
    "    analysis_results = pd.DataFrame({'Column': numeric_cols.columns, 'Z-Score Mean': z_scores.mean(), 'Z-Score Std': z_scores.std()})\n",
    "\n",
    "    # Display the analysis results in a table\n",
    "    display(analysis_results)\n",
    "\n",
    "# Call the analyze function with the provided DataFrame 'df'\n",
    "analyze(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a105cf0",
   "metadata": {},
   "source": [
    "# Categorical Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e572748",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def expand_categories(values):\n",
    "    result = []\n",
    "    s = values.value_counts()\n",
    "    t = float(len(values))\n",
    "    for v in s.index:\n",
    "        result.append(\"{}:{}%\".format(v, round(100 * (s[v] / t), 2)))\n",
    "    return \"[{}]\".format(\",\".join(result))\n",
    "        \n",
    "def analyze(df):\n",
    "    cols = df.columns.values\n",
    "    total = float(len(df))\n",
    "\n",
    "    result_data = []  # Store the analysis results in a list of dictionaries\n",
    "\n",
    "    for col in cols:\n",
    "        col_analysis = {}\n",
    "        uniques = df[col].unique()\n",
    "        unique_count = len(uniques)\n",
    "        if unique_count > 100:\n",
    "            col_analysis['Column'] = col\n",
    "            col_analysis['UniqueCount'] = unique_count\n",
    "            col_analysis['Percentage'] = int((unique_count / total) * 100)\n",
    "        else:\n",
    "            col_analysis['Column'] = col\n",
    "            col_analysis['Categories'] = expand_categories(df[col])\n",
    "        result_data.append(col_analysis)\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    result_df = pd.DataFrame(result_data)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "# Perform the analysis\n",
    "analysis_result = analyze(df)\n",
    "\n",
    "# Display the analysis results as a table\n",
    "display(analysis_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d72fad-78e0-465c-bedd-4ec93f57247f",
   "metadata": {},
   "source": [
    "# Text Encoding and Label Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a2cd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "x_columns = df.columns.drop('label')\n",
    "x = df[x_columns].values\n",
    "dummies = pd.get_dummies(df['label']) # Classification\n",
    "outcomes = dummies.columns\n",
    "num_classes = len(outcomes)\n",
    "y = dummies.values\n",
    "\n",
    "\n",
    "df.groupby('label')['label'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9a62a6",
   "metadata": {},
   "source": [
    "# Data Encoding and Normalization for Network Traffic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the encoding functions\n",
    "def encode_numeric_zscore(df, column_name):\n",
    "    df[column_name] = (df[column_name] - df[column_name].mean()) / df[column_name].std()\n",
    "\n",
    "def encode_text_dummy(df, column_name):\n",
    "    dummies = pd.get_dummies(df[column_name], prefix=column_name)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df.drop(columns=[column_name], inplace=True)\n",
    "    return df\n",
    "\n",
    "# Apply the encoding functions to the DataFrame 'df'\n",
    "encode_numeric_zscore(df, 'duration')\n",
    "#encode_numeric_zscore(df, 'protocol_type')\n",
    "#encode_numeric_zscore(df, 'service')\n",
    "encode_numeric_zscore(df, 'src_bytes')\n",
    "encode_numeric_zscore(df, 'dst_bytes')\n",
    "encode_numeric_zscore(df, 'wrong_fragment')\n",
    "encode_numeric_zscore(df, 'urgent')\n",
    "encode_numeric_zscore(df, 'hot')\n",
    "encode_numeric_zscore(df, 'num_failed_logins')\n",
    "encode_numeric_zscore(df, 'lnum_compromised')  # Corrected column name\n",
    "encode_numeric_zscore(df, 'lroot_shell')       # Corrected column name\n",
    "encode_numeric_zscore(df, 'lsu_attempted')  \n",
    "encode_numeric_zscore(df, 'num_failed_logins')\n",
    "#encode_numeric_zscore(df, 'logged_in')\n",
    "encode_numeric_zscore(df, 'lnum_shells')\n",
    "encode_numeric_zscore(df, 'num_failed_logins')\n",
    "encode_numeric_zscore(df, 'lnum_access_files')\n",
    "encode_numeric_zscore(df, 'lnum_outbound_cmds')\n",
    "encode_text_dummy(df, 'is_host_login')\n",
    "encode_text_dummy(df, 'is_guest_login')\n",
    "encode_numeric_zscore(df, 'count')\n",
    "encode_numeric_zscore(df, 'srv_count')\n",
    "encode_numeric_zscore(df, 'serror_rate')\n",
    "encode_numeric_zscore(df, 'srv_serror_rate')\n",
    "encode_numeric_zscore(df, 'rerror_rate')\n",
    "encode_numeric_zscore(df, 'srv_rerror_rate')\n",
    "encode_numeric_zscore(df, 'same_srv_rate')\n",
    "encode_numeric_zscore(df, 'diff_srv_rate')\n",
    "encode_numeric_zscore(df, 'srv_diff_host_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_count')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_count')\n",
    "encode_numeric_zscore(df, 'dst_host_same_srv_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_diff_srv_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_same_src_port_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_diff_host_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_serror_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_serror_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_rerror_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_rerror_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b0d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True,axis=1)\n",
    "df[0:494020]\n",
    "# This is the numeric feature vector, as it goes to the neural net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dec945",
   "metadata": {},
   "source": [
    "# Class Probability Analysis with One-Hot Encoding\n",
    "This code  handles categorical columns through one-hot encoding. After training the model, it prints the average probabilities for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7be3b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df.select_dtypes(include='number')\n",
    "\n",
    "# Perform one-hot encoding on categorical columns\n",
    "categorical_columns = df.select_dtypes(exclude='number')\n",
    "encoded_columns = pd.get_dummies(categorical_columns)\n",
    "\n",
    "# Concatenate numeric and encoded categorical columns\n",
    "X = pd.concat([numeric_columns, encoded_columns], axis=1)\n",
    "y = df['label']\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict probabilities for all instances in the dataset\n",
    "probabilities = model.predict_proba(X)\n",
    "\n",
    "# Calculate the average probabilities for each class\n",
    "average_probabilities = probabilities.mean(axis=0)\n",
    "\n",
    "# Display the average probabilities\n",
    "class_labels = model.classes_\n",
    "for label, prob in zip(class_labels, average_probabilities):\n",
    "    print(f'Average probability for {label}: {prob}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5b9080",
   "metadata": {},
   "source": [
    "# Binary Representation of Attack Types\n",
    "This can be useful for inspecting how the one-hot encoding transformed the categorical variable into a format suitable for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b62f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform one-hot encoding on the 'label' column\n",
    "label_dummies = pd.get_dummies(df['label'])\n",
    "\n",
    "# Print the resulting dummy variables\n",
    "print(label_dummies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10a5a28",
   "metadata": {},
   "source": [
    "# K-Means Clustering on Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9423b91f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select the features for clustering, excluding non-numeric columns\n",
    "numeric_columns = df.select_dtypes(include='number').columns\n",
    "features = df[numeric_columns].copy()\n",
    "\n",
    "# standardisation \n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(scaled_features)\n",
    "labels = kmeans.labels_\n",
    "df['cluster'] = labels\n",
    "print(df.head())\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6483dfa1-c8e0-4fa4-ad8f-d1a0953276cd",
   "metadata": {},
   "source": [
    "# Visualizing K-Means Clustering Across Multiple Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cae27c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df.select_dtypes(include='number').columns\n",
    "features = df[numeric_columns].copy()\n",
    "num_features = len(features.columns)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(scaled_features)\n",
    "labels = kmeans.labels_\n",
    "df['cluster'] = labels\n",
    "\n",
    "# Choose a random subset of features to plot\n",
    "num_features_to_plot = min(num_features, 10)  # Adjust the number as needed\n",
    "random.seed(42)\n",
    "random_features = random.sample(features.columns.tolist(), num_features_to_plot)\n",
    "\n",
    "for i in range(num_features_to_plot - 1):\n",
    "    for j in range(i + 1, num_features_to_plot):\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.scatter(scaled_features[:, features.columns.get_loc(random_features[i])],\n",
    "                    scaled_features[:, features.columns.get_loc(random_features[j])],\n",
    "                    c=labels, cmap='viridis')\n",
    "        plt.xlabel(random_features[i])\n",
    "        plt.ylabel(random_features[j])\n",
    "        plt.title(f\"Scatter plot of {random_features[i]} vs. {random_features[j]}\")\n",
    "        plt.show()\n",
    "        time.sleep(2)  # Pause for 2 seconds before displaying the next plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cf71be-093b-4efd-b62a-58241f1f509b",
   "metadata": {},
   "source": [
    "# Network Attack Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015eaa79-4ea2-44c6-ba11-e384f05f42ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature(s) you want to use for clustering\n",
    "X = df[['duration','src_bytes', 'dst_bytes','dst_host_srv_count', 'dst_host_same_srv_rate','wrong_fragment', 'logged_in', 'srv_count', \n",
    "            'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
    "            'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
    "            'dst_host_srv_rerror_rate']]\n",
    "\n",
    "# Perform K-means clustering with k=4\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(X)\n",
    "\n",
    "# Add cluster labels to the DataFrame\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "# Create a figure with subplots for each feature\n",
    "fig, axes = plt.subplots(5, 3, figsize=(15, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Define cluster label mapping\n",
    "cluster_mapping = {\n",
    "    0: 'smurf',\n",
    "    1: 'neptune',\n",
    "    2: 'normal',\n",
    "    3: 'others'\n",
    "}\n",
    "\n",
    "# Define colors for each cluster\n",
    "cluster_colors = {\n",
    "    'smurf': 'blue',\n",
    "    'neptune': 'red',\n",
    "    'normal': 'green',\n",
    "    'others': 'gray'\n",
    "}\n",
    "\n",
    "# Iterate over each feature and plot against cluster labels\n",
    "for i, feature in enumerate(X.columns):\n",
    "    scatter = axes[i].scatter(X[feature], df['cluster'], c=df['cluster'].map(cluster_mapping).map(cluster_colors))\n",
    "    axes[i].set_xlabel(feature)\n",
    "    axes[i].set_ylabel('Attack Labels')\n",
    "    axes[i].set_title(f' {feature} vs. attack labels')\n",
    "    axes[i].grid(True)\n",
    "\n",
    "# Create a single legend for all plots\n",
    "legend_scatter = []\n",
    "for cluster_label, color in cluster_colors.items():\n",
    "    legend_scatter.append(plt.Line2D([0], [0], marker='o', color='w', label=cluster_label, markerfacecolor=color, markersize=10))\n",
    "\n",
    "# Add legend outside the subplots on top\n",
    "fig.legend(handles=legend_scatter, loc='upper center', bbox_to_anchor=(0.5, 1.05), ncol=len(cluster_colors))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc544169-f055-4f91-9bcb-61c462ad7816",
   "metadata": {},
   "source": [
    "# 3D Visualization of Network Attack Types with PCA and K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce1c280-c5ca-4a5a-b7a7-0cd85140ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the 'label' column\n",
    "label_mapping = {\n",
    "    'smurf': 'smurf',\n",
    "    'neptune': 'neptune',\n",
    "    'normal': 'normal',\n",
    "}\n",
    "\n",
    "# Apply the mapping to the encoded 'label' column\n",
    "df['label_encoded'] = df['label'].map(label_mapping).fillna('others')\n",
    "\n",
    "# Define the features you want to use for clustering\n",
    "features = ['duration', 'src_bytes', 'dst_bytes']  # Add more features if needed\n",
    "X = df[features]\n",
    "\n",
    "# Perform K-means clustering with k=4\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(X)\n",
    "\n",
    "# Add cluster labels to the DataFrame\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "\n",
    "# Perform PCA with three components\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_std)\n",
    "\n",
    "# Create an interactive 3D scatter plot using Plotly Express\n",
    "fig = px.scatter_3d(df, x=X_pca[:, 0], y=X_pca[:, 1], z=X_pca[:, 2], color='cluster', labels={'color': 'Cluster'},\n",
    "                    title='Interactive 3D Scatter Plot of DOS Attacks with K-means Clusters')\n",
    "\n",
    "# Customize the appearance of the plot\n",
    "fig.update_traces(marker=dict(size=5), selector=dict(mode='markers'))\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeff0afa-116d-4dec-8d92-b714018ae8f9",
   "metadata": {},
   "source": [
    "# PCA Visualization of Network Attack Types in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19c3d82-815f-4855-9778-28e2a4dd8921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the numerical columns for PCA\n",
    "numeric_columns = df.select_dtypes(include='number').columns\n",
    "selected_data_numeric = df[numeric_columns].copy()\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(selected_data_numeric)\n",
    "\n",
    "# Perform PCA to reduce dimensions to 3D\n",
    "pca = PCA(n_components=3)\n",
    "pca_features = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Get the labels from the original DataFrame\n",
    "labels = df['label'].values\n",
    "\n",
    "# Calculate counts for each label\n",
    "label_counts = df['label'].value_counts()\n",
    "\n",
    "# Define color map based on label counts\n",
    "label_color_map = {\n",
    "    label: 'blue' if label == 'smurf' else 'red' if label == 'neptune' else 'green' if label == 'normal' else 'gray'\n",
    "    for label in label_counts.index.tolist()\n",
    "}\n",
    "\n",
    "# Assign colors to each data point based on its label\n",
    "colors = [label_color_map[label] for label in labels]\n",
    "\n",
    "# Plot the 3D PCA result with different colors for different labels\n",
    "fig = plt.figure(figsize=(7, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(pca_features[:, 0], pca_features[:, 1], pca_features[:, 2], c=colors)\n",
    "ax.set_xlabel('pca 1', fontsize=12)\n",
    "ax.set_ylabel('pca 2', fontsize=12)\n",
    "ax.set_zlabel('pca 3', fontsize=12)\n",
    "ax.set_title('')\n",
    "\n",
    "legend_elements = [\n",
    "    plt.Line2D([0], [0], marker='o', color='w', label='smurf', markerfacecolor='blue', markersize=10),\n",
    "    plt.Line2D([0], [0], marker='o', color='w', label='neptune', markerfacecolor='red', markersize=10),\n",
    "    plt.Line2D([0], [0], marker='o', color='w', label='normal', markerfacecolor='green', markersize=10),\n",
    "    plt.Line2D([0], [0], marker='o', color='w', label='others', markerfacecolor='gray', markersize=10)\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "# Reconstruction of Data (for Anomaly Detection)\n",
    "reconstructed_data = np.dot(pca_features, pca.components_)\n",
    "\n",
    "# Calculation of Reconstruction Error (for Anomaly Detection)\n",
    "reconstruction_error = np.linalg.norm(scaled_data - reconstructed_data, ord=2)\n",
    "\n",
    "print(\"Reconstruction Error:\", reconstruction_error\n",
    "\n",
    "# Adjust subplot layout to center\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58f85f8-d514-4d51-b35b-a5ae05879e91",
   "metadata": {},
   "source": [
    "# Multi-angle 3D PCA Visualization of Network Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c8fc87-7d85-4ca7-9b65-2a3b4e02446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the numerical columns for PCA\n",
    "numeric_columns = df.select_dtypes(include='number').columns\n",
    "selected_data_numeric = df[numeric_columns].copy()\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(selected_data_numeric)\n",
    "\n",
    "# Perform PCA to reduce dimensions to 3D\n",
    "pca = PCA(n_components=3)\n",
    "pca_features = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Get the labels from the original DataFrame\n",
    "label_color_map = {\n",
    "    'smurf': 'blue',\n",
    "    'neptune': 'red',\n",
    "    'normal': 'green',\n",
    "    'others': 'gray',\n",
    "}\n",
    "\n",
    "# Create a list of colors for each data point based on its label, with a default color of 'gray'\n",
    "colors = [label_color_map.get(label, 'gray') for label in df['label'].values]\n",
    "\n",
    "# Create the 3D PCA plot from different angles\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Define the viewpoints for the plots\n",
    "view_points = [\n",
    "    (30, 30),   # Default front view\n",
    "    (120, 45),  # Side view\n",
    "    (100, 180),    # Bottom view\n",
    "    (45, 360),  # Rear view\n",
    "]\n",
    "\n",
    "for i, (elev, azim) in enumerate(view_points):\n",
    "    ax = fig.add_subplot(2, 2, i + 1, projection='3d')\n",
    "    ax.scatter(pca_features[:, 0], pca_features[:, 1], pca_features[:, 2], c=colors)\n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')\n",
    "    ax.set_zlabel('PC3')\n",
    "    ax.set_title(f'')\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "\n",
    "plt.suptitle('', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7310c7-d750-40b6-9662-fa271cc695f5",
   "metadata": {},
   "source": [
    "# 3D Interactive Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe6a157-80f4-416d-a782-e2cef0a287bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the numerical columns for PCA\n",
    "numeric_columns = df.select_dtypes(include='number').columns\n",
    "selected_data_numeric = df[numeric_columns].copy()\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(selected_data_numeric)\n",
    "\n",
    "# Perform PCA to reduce dimensions to 3D\n",
    "pca = PCA(n_components=3)\n",
    "pca_features = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Get the labels from the original DataFrame\n",
    "label_color_map = {\n",
    "    'smurf': 'blue',\n",
    "    'neptune': 'red',\n",
    "    'normal': 'green',\n",
    "    'others': 'gray',\n",
    "}\n",
    "\n",
    "# Create a list of colors for each data point based on its label, with a default color of 'gray'\n",
    "colors = [label_color_map.get(label, 'gray') for label in df['label'].values]\n",
    "\n",
    "# Create a DataFrame for the PCA results\n",
    "pca_df = pd.DataFrame(pca_features, columns=['PC1', 'PC2', 'PC3'])\n",
    "pca_df['Label'] = df['label']\n",
    "\n",
    "# Plot the 3D PCA result with plotly\n",
    "fig = px.scatter_3d(\n",
    "    pca_df,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    z='PC3',\n",
    "    color='Label',\n",
    "    color_discrete_map=label_color_map,\n",
    "    title='3D PCA'\n",
    ")\n",
    "\n",
    "fig.update_layout(scene = dict(\n",
    "                    xaxis_title='Principal Component 1',\n",
    "                    yaxis_title='Principal Component 2',\n",
    "                    zaxis_title='Principal Component 3'))\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
