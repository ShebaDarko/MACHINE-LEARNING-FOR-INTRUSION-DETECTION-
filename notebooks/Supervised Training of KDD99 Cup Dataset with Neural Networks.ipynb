{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67059029",
   "metadata": {},
   "source": [
    "# Implementaton of Neural Network on KD99 data set\n",
    "\n",
    "**Author:** Bathsheba Darko \\\n",
    "**Date:** [28.06.2024]  \\\n",
    "**Description:** This notebook implements various neural network models on the KD99 dataset. It includes preprocessing, feature selection, data splitting, model training (Sequential NN, RNN, MLP), evaluation metrics, and visualization of results.\n",
    "\n",
      "**Acknowledgment:** Parts of this code were developed with the ideas from ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee2fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install feature_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637b10e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrixfrom sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb8f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the KDD99 dataset (replace 'file_path' with the actual path to your dataset file)\n",
    "\n",
    "file_path = r\"C:\\home\\data\\kddcup99_csv.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0466d0ca",
   "metadata": {},
   "source": [
    "#  Seperate features and Perform one hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4351ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (x) and labels (y) in the columns\n",
    "x_columns = df.columns.drop(['label'])\n",
    "x = df[x_columns]\n",
    "\n",
    "# Perform one-hot encoding for categorical features\n",
    "categorical_columns = x.select_dtypes(include='object').columns\n",
    "encoder = OneHotEncoder()\n",
    "encoded_columns = encoder.fit_transform(x[categorical_columns]).toarray()\n",
    "# Create column names for the one-hot encoded features\n",
    "encoded_column_names = [f\"{col}_{val}\" for col, vals in zip(categorical_columns, encoder.categories_) for val in vals]\n",
    "encoded_df = pd.DataFrame(encoded_columns, columns=encoded_column_names)\n",
    "x = pd.concat([x, encoded_df], axis=1)\n",
    "x = x.drop(categorical_columns, axis=1)\n",
    "\n",
    "# Convert the target labels to integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Convert the numpy arrays to float32\n",
    "x = x.values.astype('float32')\n",
    "y = y.values.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835ce2a6",
   "metadata": {},
   "source": [
    "# Data partitioning\n",
    "\n",
    "Splitting Data into Training and Test Sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25892897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (x) and labels (y)\n",
    "x_columns = df.columns.drop(['label'])\n",
    "x = df[x_columns]\n",
    "y = df['label']\n",
    "\n",
    "#Perform one-hot encoding for categorical features (assuming you have categorical features)\n",
    "categorical_columns = x.select_dtypes(include='object').columns\n",
    "x = pd.get_dummies(x, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Ensure you have exactly 42 columns\n",
    "if x.shape[1] != 42:\n",
    "    # Identify the columns to keep\n",
    "    columns_to_keep = x.columns[:42]\n",
    "    x = x[columns_to_keep]\n",
    "\n",
    "# Convert labels to numerical values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Standardize the features (optional but often beneficial)\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# Now you can continue with the code you provided\n",
    "# Print shapes\n",
    "print('Train data')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print('=' * 20)\n",
    "print('Test data')\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print('=' * 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4f7686-8a50-45a0-aaaa-0e7e1c79e5e5",
   "metadata": {},
   "source": [
    "# Bar Chat Plot Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3edd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the \"husl\" color palette\n",
    "custom_palette = sns.color_palette(\"husl\", len(table_data))\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the bar chart with custom colors\n",
    "plt.bar(table_data['Class'], table_data['Percentage'], color=custom_palette)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('')\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b9637-2568-45a1-b06e-dfd0cfa28cb0",
   "metadata": {},
   "source": [
    "# Table Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91d0173",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_distribution = df['label'].value_counts()\n",
    "sorted_yi = class_distribution.index\n",
    "\n",
    "# Calculating percentages\n",
    "percentages = np.round((class_distribution / df.shape[0] * 100), 3)\n",
    "\n",
    "# Create a DataFrame for the table\n",
    "table_data = pd.DataFrame({'Class': sorted_yi, 'Count': class_distribution, 'Percentage': percentages})\n",
    "table_data = table_data.sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display the table\n",
    "table_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c0133",
   "metadata": {},
   "source": [
    "# Attack Distribution in Data Partitioning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d48a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate features (x) and labels (y)\n",
    "x_columns = df.columns.drop(['label'])\n",
    "x = df[x_columns]\n",
    "y = df['label']\n",
    "\n",
    "# Perform one-hot encoding for categorical features (assuming you have categorical features)\n",
    "categorical_columns = x.select_dtypes(include='object').columns\n",
    "x = pd.get_dummies(x, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Ensure you have exactly 42 columns\n",
    "if x.shape[1] != 42:\n",
    "    # Identify the columns to keep\n",
    "    columns_to_keep = x.columns[:42]\n",
    "    x = x[columns_to_keep]\n",
    "\n",
    "# Convert labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state = 42)\n",
    "\n",
    "# Standardize the features (optional but often beneficial)\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# Print shapes\n",
    "print('Actual Data')\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print('=' * 20)\n",
    "print('Train Data')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print('=' * 20)\n",
    "print('Test Data')\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print('=' * 20)\n",
    "\n",
    "# Count of labels in the actual data\n",
    "label_distribution_actual = pd.Series(label_encoder.inverse_transform(y)).value_counts()\n",
    "print('Label Distribution in Actual Data')\n",
    "print(label_distribution_actual)\n",
    "print('=' * 20)\n",
    "\n",
    "# Count of labels in the train data\n",
    "label_distribution_train = pd.Series(label_encoder.inverse_transform(y_train)).value_counts()\n",
    "print('Label Distribution in Train Data')\n",
    "print(label_distribution_train)\n",
    "print('=' * 20)\n",
    "\n",
    "# Count of labels in the test data\n",
    "label_distribution_test = pd.Series(label_encoder.inverse_transform(y_test)).value_counts()\n",
    "print('Label Distribution in Test Data')\n",
    "print(label_distribution_test)\n",
    "print('=' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7930cda6-033f-40ae-969b-fb160f92049d",
   "metadata": {},
   "source": [
    "#  Percentage Distribution of Attack class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef3ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calculate percentages for label distribution in the train data\n",
    "label_distribution_train_percentage = (label_distribution_train / len(y_train)) * 100\n",
    "\n",
    "# Calculate percentages for label distribution in the test data\n",
    "label_distribution_test_percentage = (label_distribution_test / len(y_test)) * 100\n",
    "# Peint the label distribution in Label Distribution in Actual Data\n",
    "#print('Label Distribution in Actual Data(Percentage)')\n",
    "#print(label_distribution_actual_percentage)\n",
    "#print('=' * 20)\n",
    "\n",
    "# Print label distribution percentages in the train data\n",
    "print('Label Distribution in Train Data (Percentage)')\n",
    "print(label_distribution_train_percentage)\n",
    "print('=' * 20)\n",
    "\n",
    "# Print label distribution percentages in the test data\n",
    "print('Label Distribution in Test Data (Percentage)')\n",
    "print(label_distribution_test_percentage)\n",
    "print('=' * 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36ca47b",
   "metadata": {},
   "source": [
    "# ======== METHOD 1 : Sequential Neural Net ==============\n",
    "Here we consider the various methods for training, starting with Sequential Neural Networks (NNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6283460e",
   "metadata": {},
   "source": [
    "# Setting Up a Neural Network: Learning Rate and Model Overview\"\n",
    "\n",
    "The learning rate helps to know the step size to be take to optimsie and train the process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be79b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model with learning rate\n",
    "input_dim = x_train.shape[1]  # Number of features\n",
    "num_classes = len(df['label'].unique())  # Number of classes in the 'label' column\n",
    "\n",
    "\n",
    "# Create and compile the model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Print learning rate and model summary\n",
    "print('Learning Rate - ')\n",
    "print(K.eval(model.optimizer.lr))\n",
    "print('='*50)\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ef8e93",
   "metadata": {},
   "source": [
    "# Neural Network Setup with One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3a26b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (x) and labels (y)\n",
    "x_columns = df.columns.drop(['label'])\n",
    "x = df[x_columns]\n",
    "\n",
    "# Perform one-hot encoding for categorical features\n",
    "categorical_columns = x.select_dtypes(include='object').columns\n",
    "encoder = OneHotEncoder()\n",
    "encoded_columns = encoder.fit_transform(x[categorical_columns]).toarray()\n",
    "# Create column names for the one-hot encoded features\n",
    "encoded_column_names = [f\"{col}_{val}\" for col, vals in zip(categorical_columns, encoder.categories_) for val in vals]\n",
    "encoded_df = pd.DataFrame(encoded_columns, columns=encoded_column_names)\n",
    "x = pd.concat([x, encoded_df], axis=1)\n",
    "x = x.drop(categorical_columns, axis=1)\n",
    "\n",
    "# Convert the target labels to integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Convert the numpy arrays to float32\n",
    "x = x.values.astype('float32')\n",
    "y = y.values.astype('float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16fe25e",
   "metadata": {},
   "source": [
    "# Exploring different learning rates \n",
    "Different learning rates helps to know the convergence and which one does better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57e168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define your model\n",
    "input_dim = x_train.shape[1]\n",
    "num_classes = len(df['label'].unique())\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=x_train.shape[1], activation='relu'))\n",
    "# nb model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "# nb \n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Experiment with different learning rates\n",
    "learning_rates = [0.01, 0.0001]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nTraining with Learning Rate: {lr}\\n{'='*50}\")\n",
    "\n",
    "    # Set the learning rate in the optimizer\n",
    "    custom_optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=custom_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Print the current learning rate\n",
    "    print('Learning Rate - ')\n",
    "    print(K.eval(model.optimizer.lr)) \n",
    "\n",
    "    # Print the model summary\n",
    "    print('='*50)\n",
    "    model.summary()\n",
    "\n",
    "    # Train the model (add your training code here)\n",
    "\n",
    "    # Evaluate the model (add your evaluation code here)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77635ce7",
   "metadata": {},
   "source": [
    "# Model Training : Binary Classification\n",
    "Here we USE ADAM optimiser as the default learning rate of 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2137730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test/train split.  25% test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Create neural net\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(50, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(10, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Use 'sigmoid' activation for binary classification\n",
    "#explicictely set learning rate here with default learning rate \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  # Use binary_crossentropy for binary classification\n",
    "\n",
    "# or customize it with  optimizer for different leranong rate \n",
    "#custom_optimizer = Adam(learning_rate=0.001)\n",
    "#model.compile(loss='binary_crossentropy', optimizer=custom_optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), callbacks=[monitor], verbose=2, epochs=19)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29be2ff5",
   "metadata": {},
   "source": [
    "# Model Training : Multi Classification \n",
    "\n",
    "Categorical entropy is used categorical cross-entropy is used here for training, aligning with the multi-class classification task , where there are more than two exclusive classes or categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae004ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create neural net\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(50, input_dim=x_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(10,  input_dim=x_train.shape[1],kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, activation='softmax'))  # Use 'sigmoid' activation for binary classification\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # Use binary_crossentropy for binary classification\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), callbacks=[monitor], verbose=2, epochs=19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fc42c2",
   "metadata": {},
   "source": [
    "# Categorical Data Handling in Neural Network Classification: Confusion Matrix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6219dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate features (x) and labels (y)\n",
    "x_columns = df.columns.drop(['label'])\n",
    "x = df[x_columns]\n",
    "\n",
    "# Perform one-hot encoding for categorical features\n",
    "categorical_columns = x.select_dtypes(include='object').columns\n",
    "encoder = OneHotEncoder()\n",
    "encoded_columns = encoder.fit_transform(x[categorical_columns]).toarray()\n",
    "\n",
    "# Create column names for the one-hot encoded features\n",
    "encoded_column_names = [f\"{col}_{val}\" for col, vals in zip(categorical_columns, encoder.categories_) for val in vals]\n",
    "encoded_df = pd.DataFrame(encoded_columns, columns=encoded_column_names)\n",
    "x = pd.concat([x, encoded_df], axis=1)\n",
    "x = x.drop(categorical_columns, axis=1)\n",
    "\n",
    "# Convert the target labels to integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Convert the numpy arrays to float32\n",
    "x = x.values.astype('float32')\n",
    "y = y.values.astype('float32')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Create neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(50, input_dim=x_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(10,  input_dim=x_train.shape[1],kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, activation='softmax'))  # Use 'sigmoid' activation for binary classification\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])   # Use binary_crossentropy for binary classification\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), callbacks=[monitor], verbose=2, epochs=19)\n",
    "\n",
    "# Make predictions\n",
    "pred_probabilities = model.predict(x_test)\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "pred_labels = np.argmax(pred_probabilities, axis=1)\n",
    "\n",
    "# Now, create a confusion matrix\n",
    "label_names = label_encoder.classes_\n",
    "y_test_labels = label_encoder.inverse_transform(y_test.astype(int))\n",
    "pred_labels = label_encoder.inverse_transform(pred_labels)\n",
    "\n",
    "def confusion_matrix_func(y_true, y_pred, labels):\n",
    "    C = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_df = pd.DataFrame(C, index=labels, columns=labels)\n",
    "\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(cm_df, annot=True, annot_kws={\"size\": 12}, fmt='g', cmap='Blues')\n",
    "    plt.ylabel('Actual Class')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.title('')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot the confusion matrix\n",
    "confusion_matrix_func(y_test_labels, pred_labels, label_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9707219b",
   "metadata": {},
   "source": [
    "# Improving Confusion Matrix Analysis in Neural Network Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c34eb6-b28f-4b2b-8d6f-73af49e4b80c",
   "metadata": {},
   "source": [
    "# Sparse Categorical Neural Network: Confusion Matrix Analysis\n",
    "\n",
    "Sparse categorical cross-entropy is considered a feasible approach for handling integer-encoded labels in classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba6236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate features (x) and labels (y)\n",
    "x_columns = df.columns.drop(['label'])\n",
    "x = df[x_columns]\n",
    "\n",
    "# Perform one-hot encoding for categorical features\n",
    "categorical_columns = x.select_dtypes(include='object').columns\n",
    "encoder = OneHotEncoder()\n",
    "encoded_columns = encoder.fit_transform(x[categorical_columns]).toarray()\n",
    "\n",
    "# Create column names for the one-hot encoded features\n",
    "encoded_column_names = [f\"{col}_{val}\" for col, vals in zip(categorical_columns, encoder.categories_) for val in vals]\n",
    "encoded_df = pd.DataFrame(encoded_columns, columns=encoded_column_names)\n",
    "x = pd.concat([x, encoded_df], axis=1)\n",
    "x = x.drop(categorical_columns, axis=1)\n",
    "\n",
    "# Convert the target labels to integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Convert the numpy arrays to float32\n",
    "x = x.values.astype('float32')\n",
    "y = y.values.astype('float32')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Create neural network model, use sparse categorical cross entropy instead\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))  # Number of units matches the number of classes\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Inlude an early stopping to prevent overfitting\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), callbacks=[monitor], verbose=2, epochs=19)\n",
    "\n",
    "# Make predictions\n",
    "pred_probabilities = model.predict(x_test)\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "pred_labels = np.argmax(pred_probabilities, axis=1)\n",
    "\n",
    "# Now, lets create a confusion matrix\n",
    "label_names = label_encoder.classes_\n",
    "y_test_labels = label_encoder.inverse_transform(y_test.astype(int))\n",
    "pred_labels = label_encoder.inverse_transform(pred_labels)\n",
    "\n",
    "def confusion_matrix_func(y_true, y_pred, labels):\n",
    "    C = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_df = pd.DataFrame(C, index=labels, columns=labels)\n",
    "\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(cm_df, annot=True, annot_kws={\"size\": 12}, fmt='g', cmap='Blues')\n",
    "    plt.ylabel('Actual Class')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.title('')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot the confusion matrix\n",
    "confusion_matrix_func(y_test_labels, pred_labels, label_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f06b46-70f0-45d6-a847-a79fc0b380cc",
   "metadata": {},
   "source": [
    "# Confusion Matrix and False Positives/Negatives Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af32880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the confusion matrix function\n",
    "def confusion_matrix_func(y_true, y_pred, labels):\n",
    "    C = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_df = pd.DataFrame(C, index=labels, columns=labels)\n",
    "\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(cm_df, annot=True, annot_kws={\"size\": 12}, fmt='g', cmap='Blues')\n",
    "    plt.ylabel('Actual Class')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.title('')\n",
    "    plt.show()\n",
    "\n",
    "    # Extract FP and FN values\n",
    "    FP = cm_df.sum(axis=0) - np.diag(cm_df)\n",
    "    FN = cm_df.sum(axis=1) - np.diag(cm_df)\n",
    "\n",
    "    # Display FP and FN values in a table\n",
    "    fp_fn_table = pd.DataFrame({'False Positives': FP, 'False Negatives': FN}, index=labels)\n",
    "    print(\"\\nFalse Positives and False Negatives:\")\n",
    "    print(fp_fn_table)\n",
    "\n",
    "# Call the function to plot the confusion matrix and display FP/FN table\n",
    "confusion_matrix_func(y_test_labels, pred_labels, label_names)\n",
    "\n",
    "# Call the function to plot the confusion matrix\n",
    "confusion_matrix_func(y_test_labels, pred_labels, label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1464abf-bc9c-4e33-8d2b-5241f7cd45a9",
   "metadata": {},
   "source": [
    "# Confusion Matrix Analysis with Performance Metrics per Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8529a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_func(y_true, y_pred, labels):\n",
    "    C = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_df = pd.DataFrame(C, index=labels, columns=labels)\n",
    "\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(cm_df, annot=True, annot_kws={\"size\": 12}, fmt='g', cmap='Blues')\n",
    "    plt.ylabel('Actual Class')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.title('')\n",
    "    plt.show()\n",
    "\n",
    "    # Extract FP and FN values\n",
    "    FP = cm_df.sum(axis=0) - np.diag(cm_df)\n",
    "    FN = cm_df.sum(axis=1) - np.diag(cm_df)\n",
    "\n",
    "    # Display FP and FN values in a table\n",
    "    fp_fn_table = pd.DataFrame({'False Positives': FP, 'False Negatives': FN}, index=labels)\n",
    "    print(\"\\nFalse Positives and False Negatives:\")\n",
    "    print(fp_fn_table)\n",
    "\n",
    "    return cm_df  # Return the confusion matrix dataframe\n",
    "\n",
    "# Call the function to get the confusion matrix dataframe\n",
    "cm_df = confusion_matrix_func(y_test_labels, pred_labels, label_names)\n",
    "\n",
    "# Check if cm_df is not None\n",
    "if cm_df is not None:\n",
    "    # Calculate performance metrics for each class\n",
    "    metrics_df = pd.DataFrame(columns=['Class', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'Specificity', 'False Positive Rate', 'False Negative Rate'])\n",
    "\n",
    "    for class_label in label_names:\n",
    "        TP = cm_df.loc[class_label, class_label]\n",
    "        FP = cm_df.loc[label_names[label_names != class_label], class_label].sum()\n",
    "        FN = cm_df.loc[class_label, label_names[label_names != class_label]].sum()\n",
    "        TN = cm_df.loc[label_names[label_names != class_label], label_names[label_names != class_label]].sum().sum()\n",
    "\n",
    "        accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        specificity = TN / (FP + TN)\n",
    "        false_positive_rate = FP / (FP + TN)\n",
    "        false_negative_rate = FN / (TP + FN)\n",
    "\n",
    "        metrics_df = metrics_df.append({\n",
    "            'Class': class_label,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-Score': f1_score,\n",
    "            'Specificity': specificity,\n",
    "            'False Positive Rate': false_positive_rate,\n",
    "            'False Negative Rate': false_negative_rate\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    # Fill NaN values with 0\n",
    "    metrics_df = metrics_df.fillna(0)\n",
    "\n",
    "    # Display the metrics DataFrame\n",
    "    print(metrics_df)\n",
    "else:\n",
    "    print(\"Error: Confusion matrix dataframe is None.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b116af8",
   "metadata": {},
   "source": [
    "# Increasing the number of neurons for Sequential Neural Network training: Confusion Matrix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d725bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (x) and labels (y)\n",
    "x_columns = df.columns.drop(['label'])\n",
    "x = df[x_columns]\n",
    "\n",
    "# Perform one-hot encoding for categorical features\n",
    "categorical_columns = x.select_dtypes(include='object').columns\n",
    "encoder = OneHotEncoder()\n",
    "encoded_columns = encoder.fit_transform(x[categorical_columns]).toarray()\n",
    "\n",
    "# Create column names for the one-hot encoded features\n",
    "encoded_column_names = [f\"{col}_{val}\" for col, vals in zip(categorical_columns, encoder.categories_) for val in vals]\n",
    "encoded_df = pd.DataFrame(encoded_columns, columns=encoded_column_names)\n",
    "x = pd.concat([x, encoded_df], axis=1)\n",
    "x = x.drop(categorical_columns, axis=1)\n",
    "\n",
    "# Convert the target labels to integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Convert the numpy arrays to float32\n",
    "x = x.values.astype('float32')\n",
    "y = y.values.astype('float32')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Create neural network model and increase the number of neurons\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=x_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(25, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(25, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))  # Number of units matches the number of classes\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# include early stopping to prevent overfitting\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "# Train the model \n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), callbacks=[monitor], verbose=2, epochs=19)\n",
    "\n",
    "# Make predictions\n",
    "pred_probabilities = model.predict(x_test)\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "pred_labels = np.argmax(pred_probabilities, axis=1)\n",
    "\n",
    "# Now, create a confusion matrix\n",
    "label_names = label_encoder.classes_\n",
    "y_test_labels = label_encoder.inverse_transform(y_test.astype(int))\n",
    "pred_labels = label_encoder.inverse_transform(pred_labels)\n",
    "\n",
    "def confusion_matrix_func(y_true, y_pred, labels):\n",
    "    C = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_df = pd.DataFrame(C, index=labels, columns=labels)\n",
    "\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(cm_df, annot=True, annot_kws={\"size\": 12}, fmt='g', cmap='Blues')\n",
    "    plt.ylabel('Actual Class')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.title('')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot the confusion matrix\n",
    "confusion_matrix_func(y_test_labels, pred_labels, label_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953e6c1d-6911-46fb-9a48-47390afc4c90",
   "metadata": {},
   "source": [
    "# Evaluation Metrics : Sequential Neural Network Training with Increased Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d1d554",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate features (x) and labels (y)\n",
    "x_columns = df.columns.drop(['label'])\n",
    "x = df[x_columns]\n",
    "\n",
    "# Perform one-hot encoding for categorical features\n",
    "categorical_columns = x.select_dtypes(include='object').columns\n",
    "encoder = OneHotEncoder()\n",
    "encoded_columns = encoder.fit_transform(x[categorical_columns]).toarray()\n",
    "\n",
    "# Create column names for the one-hot encoded features\n",
    "encoded_column_names = [f\"{col}_{val}\" for col, vals in zip(categorical_columns, encoder.categories_) for val in vals]\n",
    "encoded_df = pd.DataFrame(encoded_columns, columns=encoded_column_names)\n",
    "x = pd.concat([x, encoded_df], axis=1)\n",
    "x = x.drop(categorical_columns, axis=1)\n",
    "\n",
    "# Convert the target labels to integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "# Display label distribution in train and test data with real names\n",
    "label_names = label_encoder.classes_\n",
    "y_train_labels = label_encoder.inverse_transform(y_train.astype(int))\n",
    "y_test_labels = label_encoder.inverse_transform(y_test.astype(int))\n",
    "\n",
    "# Load the pre-trained neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))  # Number of units matches the number of classes\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Set up EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model with systematic epochs\n",
    "epochs = 19\n",
    "history = model.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Make predictions using the trained model\n",
    "pred_probabilities = model.predict(x_test)\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "pred_labels = label_encoder.inverse_transform(pred_probabilities.argmax(axis=1))\n",
    "\n",
    "# Create a confusion matrix\n",
    "confusion_matrix_data = confusion_matrix(y_test_labels, pred_labels, labels=label_names)\n",
    "confusion_matrix_df = pd.DataFrame(confusion_matrix_data, index=label_names, columns=label_names)\n",
    "\n",
    "# Calculate performance metrics for each class\n",
    "metrics_df = pd.DataFrame(columns=['Class', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'Specificity', 'False Positive Rate', 'False Negative Rate'])\n",
    "\n",
    "for class_label in label_names:\n",
    "    TP = confusion_matrix_df.loc[class_label, class_label]\n",
    "    FP = confusion_matrix_df.loc[label_names[label_names != class_label], class_label].sum()\n",
    "    FN = confusion_matrix_df.loc[class_label, label_names[label_names != class_label]].sum()\n",
    "    TN = confusion_matrix_df.loc[label_names[label_names != class_label], label_names[label_names != class_label]].sum().sum()\n",
    "\n",
    "    accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    specificity = TN / (FP + TN)\n",
    "    false_positive_rate = FP / (FP + TN)\n",
    "    false_negative_rate = FN / (TP + FN)\n",
    "\n",
    "    metrics_df = metrics_df.append({\n",
    "        'Class': class_label,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1_score,\n",
    "        'Specificity': specificity,\n",
    "        'False Positive Rate': false_positive_rate,\n",
    "        'False Negative Rate': false_negative_rate\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Fill NaN values with 0\n",
    "metrics_df = metrics_df.fillna(0)\n",
    "\n",
    "# Display the metrics DataFrame\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af91eabc-99e7-4f5b-8076-35f1461d8005",
   "metadata": {},
   "source": [
    "# Visualizing Evaluation Metrics by Attack Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c40292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class names and evaluation metrics\n",
    "class_names = [\"back\", \"buffer_overflow\", \"ftp_write\", \"guess_passwd\", \"imap\",\n",
    "               \"ipsweep\", \"land\", \"loadmodule\", \"multihop\", \"neptune\", \"nmap\",\n",
    "               \"normal\", \"perl\", \"phf\", \"pod\", \"portsweep\", \"rootkit\", \"satan\",\n",
    "               \"smurf\", \"spy\", \"teardrop\", \"warezclient\", \"warezmaster\"]\n",
    "\n",
    "accuracy = [0.998308, 0.999943, 0.999968, 0.999854, 0.999951, 0.999676, 0.999992,\n",
    "            0.999976, 0.999992, 0.999628, 0.999692, 0.996267, 0.999992, 1.0, 0.999385,\n",
    "            0.999749, 0.999984, 0.9997, 0.999846, 1.0, 0.999951, 0.998907, 0.99996]\n",
    "\n",
    "precision = [0.720708, 0.0, 0.0, 0.0, 0.0, 0.900901, 0.75, 0.0, 0.0, 0.998362, 0.842105,\n",
    "             0.990198, 0.0, 0.0, 0.0, 0.968254, 0.0, 1.0, 0.999772, 0.0, 0.976834, 0.898876,\n",
    "             0.0]\n",
    "\n",
    "recall = [0.992495, 0.0, 0.0, 0.0, 0.0, 0.977199, 1.0, 0.0, 0.0, 0.999925, 0.313725,\n",
    "          0.990889, 0.0, 0.0, 0.0, 0.913858, 0.0, 0.905128, 0.999957, 0.0, 1.0, 0.577617,\n",
    "          0.0]\n",
    "\n",
    "f1_score = [0.835043, 0.0, 0.0, 0.0, 0.0, 0.9375, 0.857143, 0.0, 0.0, 0.999143, 0.457143,\n",
    "            0.990543, 0.0, 0.0, 0.0, 0.94027, 0.0, 0.950202, 0.999865, 0.0, 0.988281, 0.703297,\n",
    "            0.0]\n",
    "\n",
    "# Create index array for x-axis\n",
    "x = np.arange(len(class_names))\n",
    "\n",
    "# Plotting the metrics\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "bar_width = 0.2\n",
    "opacity = 0.8\n",
    "\n",
    "rects1 = ax.bar(x - bar_width, accuracy, bar_width, alpha=opacity, label='Accuracy')\n",
    "rects2 = ax.bar(x, precision, bar_width, alpha=opacity, label='Precision')\n",
    "rects3 = ax.bar(x + bar_width, recall, bar_width, alpha=opacity, label='Recall')\n",
    "rects4 = ax.bar(x + 2*bar_width, f1_score, bar_width, alpha=opacity, label='F1-Score')\n",
    "\n",
    "# Adding labels, title, and legend\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Evaluation Metrics by Class')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(class_names, rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babe877b-cc20-47e2-8852-0d0ff47c6d93",
   "metadata": {},
   "source": [
    "# Multi-Class Evaluation Metrics: Line Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a41fb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the class names and evaluation metrics\n",
    "class_names = [\"back\", \"buffer_overflow\", \"ftp_write\", \"guess_passwd\", \"imap\",\n",
    "               \"ipsweep\", \"land\", \"loadmodule\", \"multihop\", \"neptune\", \"nmap\",\n",
    "               \"normal\", \"perl\", \"phf\", \"pod\", \"portsweep\", \"rootkit\", \"satan\",\n",
    "               \"smurf\", \"spy\", \"teardrop\", \"warezclient\", \"warezmaster\"]\n",
    "\n",
    "accuracy = [0.998308, 0.999943, 0.999968, 0.999854, 0.999951, 0.999676, 0.999992,\n",
    "            0.999976, 0.999992, 0.999628, 0.999692, 0.996267, 0.999992, 1.0, 0.999385,\n",
    "            0.999749, 0.999984, 0.9997, 0.999846, 1.0, 0.999951, 0.998907, 0.99996]\n",
    "\n",
    "precision = [0.720708, 0.0, 0.0, 0.0, 0.0, 0.900901, 0.75, 0.0, 0.0, 0.998362, 0.842105,\n",
    "             0.990198, 0.0, 0.0, 0.0, 0.968254, 0.0, 1.0, 0.999772, 0.0, 0.976834, 0.898876,\n",
    "             0.0]\n",
    "\n",
    "recall = [0.992495, 0.0, 0.0, 0.0, 0.0, 0.977199, 1.0, 0.0, 0.0, 0.999925, 0.313725,\n",
    "          0.990889, 0.0, 0.0, 0.0, 0.913858, 0.0, 0.905128, 0.999957, 0.0, 1.0, 0.577617,\n",
    "          0.0]\n",
    "\n",
    "f1_score = [0.835043, 0.0, 0.0, 0.0, 0.0, 0.9375, 0.857143, 0.0, 0.0, 0.999143, 0.457143,\n",
    "            0.990543, 0.0, 0.0, 0.0, 0.94027, 0.0, 0.950202, 0.999865, 0.0, 0.988281, 0.703297,\n",
    "            0.0]\n",
    "\n",
    "# Create index array for x-axis\n",
    "x = np.arange(len(class_names))\n",
    "\n",
    "# Plotting the curves\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.plot(x, accuracy, marker='o', label='Accuracy')\n",
    "plt.plot(x, precision, marker='o', label='Precision')\n",
    "plt.plot(x, recall, marker='o', label='Recall')\n",
    "plt.plot(x, f1_score, marker='o', label='F1-Score')\n",
    "\n",
    "# Adding labels, title, and legend\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Evaluation Metrics by Class')\n",
    "plt.xticks(x, class_names, rotation=90)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995fb247-974d-40d8-9b43-c50b52cbdb77",
   "metadata": {},
   "source": [
    "# Variation of Evaluation Metrics (Accuracy, Precision, Recall, and F1-Score) Across Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476a9b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the class names and evaluation metrics\n",
    "class_names = [\"back\", \"buffer_overflow\", \"ftp_write\", \"guess_passwd\", \"imap\",\n",
    "               \"ipsweep\", \"land\", \"loadmodule\", \"multihop\", \"neptune\", \"nmap\",\n",
    "               \"normal\", \"perl\", \"phf\", \"pod\", \"portsweep\", \"rootkit\", \"satan\",\n",
    "               \"smurf\", \"spy\", \"teardrop\", \"warezclient\", \"warezmaster\"]\n",
    "\n",
    "accuracy = [0.998308, 0.999943, 0.999968, 0.999854, 0.999951, 0.999676, 0.999992,\n",
    "            0.999976, 0.999992, 0.999628, 0.999692, 0.996267, 0.999992, 1.0, 0.999385,\n",
    "            0.999749, 0.999984, 0.9997, 0.999846, 1.0, 0.999951, 0.998907, 0.99996]\n",
    "\n",
    "precision = [0.720708, 0.0, 0.0, 0.0, 0.0, 0.900901, 0.75, 0.0, 0.0, 0.998362, 0.842105,\n",
    "             0.990198, 0.0, 0.0, 0.0, 0.968254, 0.0, 1.0, 0.999772, 0.0, 0.976834, 0.898876,\n",
    "             0.0]\n",
    "\n",
    "recall = [0.992495, 0.0, 0.0, 0.0, 0.0, 0.977199, 1.0, 0.0, 0.0, 0.999925, 0.313725,\n",
    "          0.990889, 0.0, 0.0, 0.0, 0.913858, 0.0, 0.905128, 0.999957, 0.0, 1.0, 0.577617,\n",
    "          0.0]\n",
    "\n",
    "f1_score = [0.835043, 0.0, 0.0, 0.0, 0.0, 0.9375, 0.857143, 0.0, 0.0, 0.999143, 0.457143,\n",
    "            0.990543, 0.0, 0.0, 0.0, 0.94027, 0.0, 0.950202, 0.999865, 0.0, 0.988281, 0.703297,\n",
    "            0.0]\n",
    "\n",
    "# Create index array for x-axis\n",
    "x = np.arange(len(class_names))\n",
    "\n",
    "# Plotting individual curves for each metric\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(x, accuracy, marker='o', label='Accuracy')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy by Class')\n",
    "plt.xticks(x, class_names, rotation=90)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(x, precision, marker='o', label='Precision')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision by Class')\n",
    "plt.xticks(x, class_names, rotation=90)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(x, recall, marker='o', label='Recall')\n",
    "plt.plot(x, f1_score, marker='o', label='F1-Score')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Recall and F1-Score by Class')\n",
    "plt.xticks(x, class_names, rotation=90)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd97ceb0-88aa-4853-ba63-bb9e2e2c6d0e",
   "metadata": {},
   "source": [
    "# Comprehensive Evaluation Metrics by Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41d6f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Plotting accuracy, precision, recall, and F1-Score\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.barplot(data=metrics_df, x='Class', y='Accuracy')\n",
    "plt.title('Accuracy by Class')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.barplot(data=metrics_df, x='Class', y='Precision')\n",
    "plt.title('Precision by Class')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.barplot(data=metrics_df, x='Class', y='Recall')\n",
    "plt.title('Recall by Class')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.barplot(data=metrics_df, x='Class', y='F1-Score')\n",
    "plt.title('F1-Score by Class')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plotting Specificity, False Positive Rate, and False Negative Rate using a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "metrics_subset = metrics_df[['Specificity', 'False Positive Rate', 'False Negative Rate']].copy()\n",
    "metrics_subset['Class'] = metrics_df['Class']\n",
    "\n",
    "# Set the 'Class' column as index for better visualization\n",
    "metrics_subset.set_index('Class', inplace=True)\n",
    "sns.heatmap(metrics_subset, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Metrics by Class')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75562902",
   "metadata": {},
   "source": [
    "# Model Evaluation : Overall Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a6f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "evaluation_result = model.evaluate(x_test, y_test)\n",
    "print(f\"\\nEvaluation Result:\\nLoss: {evaluation_result[0]}, Accuracy: {evaluation_result[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be7094-88fe-455d-8f1d-68d4b77ff557",
   "metadata": {},
   "source": [
    "# ======== METHOD 2 : RNN Model===============\n",
    "The RNN method with Long Short-Term Memory (LSTM) was used to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13951ee2-eafe-4e55-964c-bd48f0ab493b",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network with 60 LSTM Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199ba8ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separate features (x) and labels (y)\n",
    "x_columns = df.columns.drop(['label'])\n",
    "x = df[x_columns]\n",
    "\n",
    "\n",
    "\n",
    "# Perform one-hot encoding for categorical features\n",
    "categorical_columns = x.select_dtypes(include='object').columns\n",
    "encoder = OneHotEncoder()\n",
    "encoded_columns = encoder.fit_transform(x[categorical_columns]).toarray()\n",
    "\n",
    "# Create column names for the one-hot encoded features\n",
    "encoded_column_names = [f\"{col}_{val}\" for col, vals in zip(categorical_columns, encoder.categories_) for val in vals]\n",
    "encoded_df = pd.DataFrame(encoded_columns, columns=encoded_column_names)\n",
    "x = pd.concat([x, encoded_df], axis=1)\n",
    "x = x.drop(categorical_columns, axis=1)\n",
    "\n",
    "# Convert the target labels to integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Convert the numpy arrays to float32\n",
    "x = x.values.astype('float32')\n",
    "y = y.values.astype('float32')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "# Reshape the input data for LSTM\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "# Create recurrent neural network model\n",
    "model = Sequential()\n",
    "model.add(LSTM(60, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))  # Number of units matches the number of classes\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), callbacks=[monitor], verbose=2, epochs=19)\n",
    "\n",
    "# Make predictions\n",
    "pred_probabilities = model.predict(x_test)\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "pred_labels = np.argmax(pred_probabilities, axis=1)\n",
    "\n",
    "# Now, create a confusion matrix\n",
    "label_names = label_encoder.classes_\n",
    "y_test_labels = label_encoder.inverse_transform(y_test.astype(int))\n",
    "pred_labels = label_encoder.inverse_transform(pred_labels)\n",
    "\n",
    "def confusion_matrix_func(y_true, y_pred, labels):\n",
    "    C = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_df = pd.DataFrame(C, index=labels, columns=labels)\n",
    "\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(cm_df, annot=True, annot_kws={\"size\": 12}, fmt='g', cmap='Blues')\n",
    "    plt.ylabel('Actual Class')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.title('')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot the confusion matrix\n",
    "confusion_matrix_func(y_test_labels, pred_labels, label_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4b39ff",
   "metadata": {},
   "source": [
    "# Increasing the number of neurons in Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d80bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate features (x) and labels (y)\n",
    "x_columns = df.columns.drop(['label'])\n",
    "x = df[x_columns]\n",
    "\n",
    "# Perform one-hot encoding for categorical features\n",
    "categorical_columns = x.select_dtypes(include='object').columns\n",
    "encoder = OneHotEncoder()\n",
    "encoded_columns = encoder.fit_transform(x[categorical_columns]).toarray()\n",
    "\n",
    "# Create column names for the one-hot encoded features\n",
    "encoded_column_names = [f\"{col}_{val}\" for col, vals in zip(categorical_columns, encoder.categories_) for val in vals]\n",
    "encoded_df = pd.DataFrame(encoded_columns, columns=encoded_column_names)\n",
    "x = pd.concat([x, encoded_df], axis=1)\n",
    "x = x.drop(categorical_columns, axis=1)\n",
    "\n",
    "# Convert the target labels to integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Convert the numpy arrays to float32\n",
    "x = x.values.astype('float32')\n",
    "y = y.values.astype('float32')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "# Reshape the input data for LSTM\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "# Create recurrent neural network model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))  # Number of units matches the number of classes\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), callbacks=[monitor], verbose=2, epochs=19)\n",
    "\n",
    "# Make predictions\n",
    "pred_probabilities = model.predict(x_test)\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "pred_labels = np.argmax(pred_probabilities, axis=1)\n",
    "\n",
    "# Now, create a confusion matrix\n",
    "label_names = label_encoder.classes_\n",
    "y_test_labels = label_encoder.inverse_transform(y_test.astype(int))\n",
    "pred_labels = label_encoder.inverse_transform(pred_labels)\n",
    "\n",
    "def confusion_matrix_func(y_true, y_pred, labels):\n",
    "    C = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_df = pd.DataFrame(C, index=labels, columns=labels)\n",
    "\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(cm_df, annot=True, annot_kws={\"size\": 12}, fmt='g', cmap='Blues')\n",
    "    plt.ylabel('Actual Class')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.title('')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot the confusion matrix\n",
    "confusion_matrix_func(y_test_labels, pred_labels, label_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21536df-aeaf-46b4-b15a-89f22a1e62e7",
   "metadata": {},
   "source": [
    "# Evaluation Metrics for Recurrent Neural Network (RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcaab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_func(y_true, y_pred, labels):\n",
    "    C = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_df = pd.DataFrame(C, index=labels, columns=labels)\n",
    "\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(cm_df, annot=True, annot_kws={\"size\": 12}, fmt='g', cmap='Blues')\n",
    "    plt.ylabel('Actual Class')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.title('')\n",
    "    plt.show()\n",
    "\n",
    "    # Extract TP, FP, and FN values\n",
    "    TP = np.diag(cm_df)\n",
    "    FP = cm_df.sum(axis=0) - TP\n",
    "    FN = cm_df.sum(axis=1) - TP\n",
    "\n",
    "    # Display TP, FP, and FN values in a table\n",
    "    tp_fp_fn_table = pd.DataFrame({'True Positives': TP, 'False Positives': FP, 'False Negatives': FN}, index=labels)\n",
    "    print(\"\\nTrue Positives, False Positives, and False Negatives:\")\n",
    "    print(tp_fp_fn_table)\n",
    "\n",
    "    return cm_df  # Return the confusion matrix dataframe\n",
    "\n",
    "# Call the function to get the confusion matrix dataframe\n",
    "cm_df = confusion_matrix_func(y_test_labels, pred_labels, label_names)\n",
    "\n",
    "# Check if cm_df is not None\n",
    "if cm_df is not None:\n",
    "    # Calculate performance metrics for each class\n",
    "    metrics_df = pd.DataFrame(columns=['Class', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'Specificity', 'False Positive Rate', 'False Negative Rate'])\n",
    "\n",
    "    for class_label in label_names:\n",
    "        TP = cm_df.loc[class_label, class_label]\n",
    "        FP = cm_df.loc[label_names[label_names != class_label], class_label].sum()\n",
    "        FN = cm_df.loc[class_label, label_names[label_names != class_label]].sum()\n",
    "        TN = cm_df.loc[label_names[label_names != class_label], label_names[label_names != class_label]].sum().sum()\n",
    "\n",
    "        accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        specificity = TN / (FP + TN)\n",
    "        false_positive_rate = FP / (FP + TN)\n",
    "        false_negative_rate = FN / (TP + FN)\n",
    "\n",
    "        metrics_df = metrics_df.append({\n",
    "            'Class': class_label,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-Score': f1_score,\n",
    "            'Specificity': specificity,\n",
    "            'False Positive Rate': false_positive_rate,\n",
    "            'False Negative Rate': false_negative_rate\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    # Fill NaN values with 0\n",
    "    metrics_df = metrics_df.fillna(0)\n",
    "\n",
    "    # Display the metrics DataFrame\n",
    "    print(metrics_df)\n",
    "else:\n",
    "    print(\"Error: Confusion matrix dataframe is None.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328f7f49-3251-445a-9948-41a725296fd3",
   "metadata": {},
   "source": [
    "# Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d38797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Print the total accuracy and loss\n",
    "print(\"Total Loss:\", loss)\n",
    "print(\"Total Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95854597-b31d-4bd7-9083-3239be019582",
   "metadata": {},
   "source": [
    "# Reiterating RNN and Perfomance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a33e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics for each class\n",
    "metrics_df = pd.DataFrame(columns=['Class', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'Specificity', 'False Positive Rate', 'False Negative Rate'])\n",
    "\n",
    "for class_label in label_names:\n",
    "    TP = confusion_matrix_df.loc[class_label, class_label]\n",
    "    FP = confusion_matrix_df.loc[label_names[label_names != class_label], class_label].sum()\n",
    "    FN = confusion_matrix_df.loc[class_label, label_names[label_names != class_label]].sum()\n",
    "    TN = confusion_matrix_df.loc[label_names[label_names != class_label], label_names[label_names != class_label]].sum().sum()\n",
    "\n",
    "    accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    specificity = TN / (FP + TN)\n",
    "    false_positive_rate = FP / (FP + TN)\n",
    "    false_negative_rate = FN / (TP + FN)\n",
    "\n",
    "    metrics_df = metrics_df.append({\n",
    "        'Class': class_label,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1_score,\n",
    "        'Specificity': specificity,\n",
    "        'False Positive Rate': false_positive_rate,\n",
    "        'False Negative Rate': false_negative_rate\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Fill NaN values with 0\n",
    "metrics_df = metrics_df.fillna(0)\n",
    "\n",
    "# Display the metrics DataFrame\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87ae2d9-69c8-4065-8bcc-95e31321ab71",
   "metadata": {},
   "source": [
    "# Re-Training and Variability in RNN Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448dec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (x) and labels (y)\n",
    "x_columns = df.columns.drop(['label'])\n",
    "x = df[x_columns]\n",
    "\n",
    "# Perform one-hot encoding for categorical features\n",
    "categorical_columns = x.select_dtypes(include='object').columns\n",
    "encoder = OneHotEncoder()\n",
    "encoded_columns = encoder.fit_transform(x[categorical_columns]).toarray()\n",
    "\n",
    "# Create column names for the one-hot encoded features\n",
    "encoded_column_names = [f\"{col}_{val}\" for col, vals in zip(categorical_columns, encoder.categories_) for val in vals]\n",
    "encoded_df = pd.DataFrame(encoded_columns, columns=encoded_column_names)\n",
    "x = pd.concat([x, encoded_df], axis=1)\n",
    "x = x.drop(categorical_columns, axis=1)\n",
    "\n",
    "# Convert the target labels to integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Convert the numpy arrays to float32\n",
    "x = x.values.astype('float32')\n",
    "y = y.values.astype('float32')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "# Reshape the input data for LSTM\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "# Create recurrent neural network model\n",
    "model = Sequential()\n",
    "model.add(LSTM(60, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))  # Number of units matches the number of classes\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), callbacks=[monitor], verbose=2, epochs=19)\n",
    "\n",
    "# Make predictions\n",
    "pred_probabilities = model.predict(x_test)\n",
    "\n",
    "# Create a confusion matrix\n",
    "confusion_matrix_data = confusion_matrix(y_test_labels, pred_labels, labels=label_names)\n",
    "confusion_matrix_df = pd.DataFrame(confusion_matrix_data, index=label_names, columns=label_names)\n",
    "\n",
    "# Calculate performance metrics for each class\n",
    "metrics_df = pd.DataFrame(columns=['Class', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'Specificity', 'False Positive Rate', 'False Negative Rate'])\n",
    "\n",
    "for class_label in label_names:\n",
    "    TP = confusion_matrix_df.loc[class_label, class_label]\n",
    "    FP = confusion_matrix_df.loc[label_names[label_names != class_label], class_label].sum()\n",
    "    FN = confusion_matrix_df.loc[class_label, label_names[label_names != class_label]].sum()\n",
    "    TN = confusion_matrix_df.loc[label_names[label_names != class_label], label_names[label_names != class_label]].sum().sum()\n",
    "\n",
    "    accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    specificity = TN / (FP + TN)\n",
    "    false_positive_rate = FP / (FP + TN)\n",
    "    false_negative_rate = FN / (TP + FN)\n",
    "\n",
    "    metrics_df = metrics_df.append({\n",
    "        'Class': class_label,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1_score,\n",
    "        'Specificity': specificity,\n",
    "        'False Positive Rate': false_positive_rate,\n",
    "        'False Negative Rate': false_negative_rate\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Fill NaN values with 0\n",
    "metrics_df = metrics_df.fillna(0)\n",
    "\n",
    "# Display the metrics DataFrame\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07f6e72-8273-490e-9324-f285f4562d3f",
   "metadata": {},
   "source": [
    " # ======== METHOD 3 : MLP (Feed Forward NN) =============="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301bca3f",
   "metadata": {},
   "source": [
    "This type of network is a general-purpose feedforward neural network commonly used for classification tasks when dealing with tabular data. For this study it is also seen as MLP\n",
    "\n",
    "It's worth noting that the specific architecture (number of hidden layers, number of neurons per layer, activation functions) can be adjusted based on the problem at hand and the characteristics of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb986ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate features (x) and labels (y)\n",
    "x_columns = df.columns.drop(['label'])\n",
    "x = df[x_columns]\n",
    "\n",
    "# Perform one-hot encoding for categorical features\n",
    "categorical_columns = x.select_dtypes(include='object').columns\n",
    "encoder = OneHotEncoder()\n",
    "encoded_columns = encoder.fit_transform(x[categorical_columns]).toarray()\n",
    "\n",
    "# Create column names for the one-hot encoded features\n",
    "encoded_column_names = [f\"{col}_{val}\" for col, vals in zip(categorical_columns, encoder.categories_) for val in vals]\n",
    "encoded_df = pd.DataFrame(encoded_columns, columns=encoded_column_names)\n",
    "x = pd.concat([x, encoded_df], axis=1)\n",
    "x = x.drop(categorical_columns, axis=1)\n",
    "\n",
    "# Convert the target labels to integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Convert the numpy arrays to float32\n",
    "x = x.values.astype('float32')\n",
    "y = y.values.astype('float32')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "# Define input layer\n",
    "inputs = Input(shape=(x_train.shape[1],))\n",
    "\n",
    "# Define hidden layers\n",
    "hidden1 = Dense(10, activation='relu')(inputs)\n",
    "hidden2 = Dense(50, activation='relu')(hidden1)\n",
    "hidden3 = Dense(10, activation='relu')(hidden2)\n",
    "\n",
    "# Define output layer\n",
    "outputs = Dense(len(label_encoder.classes_), activation='softmax')(hidden3)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), callbacks=[monitor], verbose=2, epochs=19)\n",
    "\n",
    "# Make predictions\n",
    "pred_probabilities = model.predict(x_test)\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "pred_labels = np.argmax(pred_probabilities, axis=1)\n",
    "\n",
    "# Now, create a confusion matrix\n",
    "label_names = label_encoder.classes_\n",
    "y_test_labels = label_encoder.inverse_transform(y_test.astype(int))\n",
    "pred_labels = label_encoder.inverse_transform(pred_labels)\n",
    "\n",
    "def confusion_matrix_func(y_true, y_pred, labels):\n",
    "    C = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_df = pd.DataFrame(C, index=labels, columns=labels)\n",
    "\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(cm_df, annot=True, annot_kws={\"size\": 12}, fmt='g', cmap='Blues')\n",
    "    plt.ylabel('Actual Class')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.title('')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot the confusion matrix\n",
    "confusion_matrix_func(y_test_labels, pred_labels, label_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f522ecd9-8f0e-4339-b1b8-b06b770c7274",
   "metadata": {},
   "source": [
    "# Evaluation Metrics for feed forward MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6213c63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_func(y_true, y_pred, labels):\n",
    "    C = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_df = pd.DataFrame(C, index=labels, columns=labels)\n",
    "\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(cm_df, annot=True, annot_kws={\"size\": 12}, fmt='g', cmap='Blues')\n",
    "    plt.ylabel('Actual Class')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.title('')\n",
    "    plt.show()\n",
    "\n",
    "    # Extract TP, FP, and FN values\n",
    "    TP = np.diag(cm_df)\n",
    "    FP = cm_df.sum(axis=0) - TP\n",
    "    FN = cm_df.sum(axis=1) - TP\n",
    "\n",
    "    # Display TP, FP, and FN values in a table\n",
    "    tp_fp_fn_table = pd.DataFrame({'True Positives': TP, 'False Positives': FP, 'False Negatives': FN}, index=labels)\n",
    "    print(\"\\nTrue Positives, False Positives, and False Negatives:\")\n",
    "    print(tp_fp_fn_table)\n",
    "\n",
    "    return cm_df  # Return the confusion matrix dataframe\n",
    "\n",
    "# Call the function to get the confusion matrix dataframe\n",
    "cm_df = confusion_matrix_func(y_test_labels, pred_labels, label_names)\n",
    "\n",
    "# Check if cm_df is not None\n",
    "if cm_df is not None:\n",
    "    # Calculate performance metrics for each class\n",
    "    metrics_df = pd.DataFrame(columns=['Class', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'Specificity', 'False Positive Rate', 'False Negative Rate'])\n",
    "\n",
    "    for class_label in label_names:\n",
    "        TP = cm_df.loc[class_label, class_label]\n",
    "        FP = cm_df.loc[label_names[label_names != class_label], class_label].sum()\n",
    "        FN = cm_df.loc[class_label, label_names[label_names != class_label]].sum()\n",
    "        TN = cm_df.loc[label_names[label_names != class_label], label_names[label_names != class_label]].sum().sum()\n",
    "\n",
    "        accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        specificity = TN / (FP + TN)\n",
    "        false_positive_rate = FP / (FP + TN)\n",
    "        false_negative_rate = FN / (TP + FN)\n",
    "\n",
    "        metrics_df = metrics_df.append({\n",
    "            'Class': class_label,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-Score': f1_score,\n",
    "            'Specificity': specificity,\n",
    "            'False Positive Rate': false_positive_rate,\n",
    "            'False Negative Rate': false_negative_rate\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    # Fill NaN values with 0\n",
    "    metrics_df = metrics_df.fillna(0)\n",
    "\n",
    "    # Display the metrics DataFrame\n",
    "    print(metrics_df)\n",
    "else:\n",
    "    print(\"Error: Confusion matrix dataframe is None.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4324929d",
   "metadata": {},
   "source": [
    "# Variability in Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6c559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics for each class\n",
    "metrics_df = pd.DataFrame(columns=['Class', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'Specificity', 'False Positive Rate', 'False Negative Rate'])\n",
    "\n",
    "for class_label in label_names:\n",
    "    TP = confusion_matrix_df.loc[class_label, class_label]\n",
    "    FP = confusion_matrix_df.loc[label_names[label_names != class_label], class_label].sum()\n",
    "    FN = confusion_matrix_df.loc[class_label, label_names[label_names != class_label]].sum()\n",
    "    TN = confusion_matrix_df.loc[label_names[label_names != class_label], label_names[label_names != class_label]].sum().sum()\n",
    "\n",
    "    accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    specificity = TN / (FP + TN)\n",
    "    false_positive_rate = FP / (FP + TN)\n",
    "    false_negative_rate = FN / (TP + FN)\n",
    "\n",
    "    metrics_df = metrics_df.append({\n",
    "        'Class': class_label,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1_score,\n",
    "        'Specificity': specificity,\n",
    "        'False Positive Rate': false_positive_rate,\n",
    "        'False Negative Rate': false_negative_rate\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Fill NaN values with 0\n",
    "metrics_df = metrics_df.fillna(0)\n",
    "\n",
    "# Display the metrics DataFrame\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10055a96-313c-4d83-88eb-866a36dba153",
   "metadata": {},
   "source": [
    "# Re-Training and Variability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f142ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate features (x) and labels (y)\n",
    "x_columns = df.columns.drop(['label'])\n",
    "x = df[x_columns]\n",
    "\n",
    "# Perform one-hot encoding for categorical features\n",
    "categorical_columns = x.select_dtypes(include='object').columns\n",
    "encoder = OneHotEncoder()\n",
    "encoded_columns = encoder.fit_transform(x[categorical_columns]).toarray()\n",
    "\n",
    "# Create column names for the one-hot encoded features\n",
    "encoded_column_names = [f\"{col}_{val}\" for col, vals in zip(categorical_columns, encoder.categories_) for val in vals]\n",
    "encoded_df = pd.DataFrame(encoded_columns, columns=encoded_column_names)\n",
    "x = pd.concat([x, encoded_df], axis=1)\n",
    "x = x.drop(categorical_columns, axis=1)\n",
    "\n",
    "# Convert the target labels to integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Convert the numpy arrays to float32\n",
    "x = x.values.astype('float32')\n",
    "y = y.values.astype('float32')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "# Define input layer\n",
    "inputs = Input(shape=(x_train.shape[1],))\n",
    "\n",
    "# Define hidden layers\n",
    "hidden1 = Dense(10, activation='relu')(inputs)\n",
    "hidden2 = Dense(50, activation='relu')(hidden1)\n",
    "hidden3 = Dense(10, activation='relu')(hidden2)\n",
    "\n",
    "# Define output layer\n",
    "outputs = Dense(len(label_encoder.classes_), activation='softmax')(hidden3)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), callbacks=[monitor], verbose=2, epochs=19)\n",
    "\n",
    "# Make predictions\n",
    "pred_probabilities = model.predict(x_test)\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "pred_labels = label_encoder.inverse_transform(pred_probabilities.argmax(axis=1))\n",
    "\n",
    "# Create a confusion matrix\n",
    "confusion_matrix_data = confusion_matrix(y_test_labels, pred_labels, labels=label_names)\n",
    "confusion_matrix_df = pd.DataFrame(confusion_matrix_data, index=label_names, columns=label_names)\n",
    "\n",
    "# Calculate performance metrics for each class\n",
    "metrics_df = pd.DataFrame(columns=['Class', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'Specificity', 'False Positive Rate', 'False Negative Rate'])\n",
    "\n",
    "for class_label in label_names:\n",
    "    TP = confusion_matrix_df.loc[class_label, class_label]\n",
    "    FP = confusion_matrix_df.loc[label_names[label_names != class_label], class_label].sum()\n",
    "    FN = confusion_matrix_df.loc[class_label, label_names[label_names != class_label]].sum()\n",
    "    TN = confusion_matrix_df.loc[label_names[label_names != class_label], label_names[label_names != class_label]].sum().sum()\n",
    "\n",
    "    accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    specificity = TN / (FP + TN)\n",
    "    false_positive_rate = FP / (FP + TN)\n",
    "    false_negative_rate = FN / (TP + FN)\n",
    "\n",
    "    metrics_df = metrics_df.append({\n",
    "        'Class': class_label,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1_score,\n",
    "        'Specificity': specificity,\n",
    "        'False Positive Rate': false_positive_rate,\n",
    "        'False Negative Rate': false_negative_rate\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Fill NaN values with 0\n",
    "metrics_df = metrics_df.fillna(0)\n",
    "\n",
    "# Display the metrics DataFrame\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e1ac07-c2f6-463b-b85f-5d924339dbb6",
   "metadata": {},
   "source": [
    "# Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cdef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Print the total accuracy and loss\n",
    "print(\"Total Loss:\", loss)\n",
    "print(\"Total Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9012fd3f-612c-48c0-8bc6-764886fa3ac6",
   "metadata": {},
   "source": [
    "# Analyzing Confidence Distributions\n",
    "\n",
    "The confidence scores reveal how certain the model is about its predictions. Higher scores indicate strong confidence in accuracy, while lower scores signify uncertainty, especially with unfamiliar data. Understanding these scores helps gauge how well the model generalizes and makes reliable decisions based on its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6e717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Extract Logits\n",
    "# Replace this with your actual trained models and test data\n",
    "def get_logits(model, test_data):\n",
    "    # Example: Get logits from a trained model\n",
    "    logits = model.predict(test_data)\n",
    "    return logits\n",
    "\n",
    "# Step 3: Apply Softmax\n",
    "def apply_softmax(logits):\n",
    "    # Apply softmax to logits\n",
    "    probabilities = np.exp(logits) / np.sum(np.exp(logits), axis=-1, keepdims=True)\n",
    "    return probabilities\n",
    "\n",
    "# Step 4: Compute Confidence Scores\n",
    "def compute_confidence(probabilities):\n",
    "    # Compute confidence scores (maximum probability across classes)\n",
    "    confidence = np.max(probabilities, axis=1)\n",
    "    return confidence\n",
    "\n",
    "# Step 5: Histogram or Density Plot for Confidence Distributions\n",
    "def plot_confidence_distribution(confidence_scores):\n",
    "    # Plot histogram or density plot for confidence scores\n",
    "    plt.figure()\n",
    "    plt.hist(confidence_scores, bins=30, density=True)\n",
    "    plt.title(\"\")\n",
    "    plt.xlabel(\"Confidence Score\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example test data\n",
    "    test_data = np.random.rand(int(0.25 * 494020), 42)  # Example test data shape (25% of total samples, 42 features)\n",
    "    \n",
    "    # Load your dataset with the actual labels\n",
    "    # Replace this with your actual dataset path\n",
    "    file_path = r\"C:\\home\\data\\kddcup99_csv.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Extract unique class names from the 'label' column\n",
    "    class_names = df['label'].unique()\n",
    "\n",
    "    # Example logits obtained from a trained model\n",
    "    logits = np.random.rand(int(0.25 * 494020), len(class_names))  # Example logits shape (25% of total samples, number of classes)\n",
    "\n",
    "    # Step 3: Apply Softmax\n",
    "    probabilities = apply_softmax(logits)\n",
    "\n",
    "    # Step 4: Compute Confidence Scores\n",
    "    confidence_scores = compute_confidence(probabilities)\n",
    "\n",
    "    # Step 5: Plot Confidence Distribution\n",
    "    plot_confidence_distribution(confidence_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a456660b-e313-4dd6-b2b1-b106e66a1e4b",
   "metadata": {},
   "source": [
    "# ======= METHOD 4 : MLP Classifier :  Confusion Matrix ======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd73089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming x and y are your feature and target matrices, respectively\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "# Assuming you are using a neural network model\n",
    "model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=100, activation='relu', solver='adam')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "# Calculate and print the ROC-AUC score\n",
    "def multiclass_roc_auc_score(y_test, pred, average=\"macro\"):\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_bin = lb.transform(y_test)\n",
    "    pred_bin = lb.transform(pred)\n",
    "    return roc_auc_score(y_test_bin, pred_bin, average=average)\n",
    "\n",
    "roc_auc = multiclass_roc_auc_score(y_test, pred, average=\"macro\")\n",
    "print(f'ROC-AUC Score: {roc_auc}')\n",
    "\n",
    "# Now, create a confusion matrix\n",
    "label_names = ['smurf', 'neptune', 'normal', 'back', 'satan', 'ipsweep', 'portsweep', 'warezclient', 'teardrop', 'pod', 'nmap', 'guess_passwd', 'butter_overflow', 'land', 'warezmaster', 'imap', 'rootkit', 'loadmodule', 'ftp_write', 'multihop', 'phf', 'perl', 'spy']\n",
    "y_test_labels = [label_names[int(label)] for label in y_test]\n",
    "pred_labels = [label_names[int(label)] for label in pred]\n",
    "\n",
    "def confusion_matrix_func(y_true, y_pred, labels):\n",
    "    C = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_df = pd.DataFrame(C, index=labels, columns=labels)\n",
    "\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(cm_df, annot=True, annot_kws={\"size\": 12}, fmt='g', cmap='Blues')\n",
    "    plt.ylabel('Actual Class')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot the confusion matrix\n",
    "confusion_matrix_func(y_test_labels, pred_labels, label_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793bfe71-c8ca-4651-8946-0c88c8cdd94a",
   "metadata": {},
   "source": [
    "# Re-iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bdfe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (x) and labels (y)\n",
    "x_columns = df.columns.drop(['label'])\n",
    "x = df[x_columns]\n",
    "\n",
    "# Perform one-hot encoding for categorical features\n",
    "categorical_columns = x.select_dtypes(include='object').columns\n",
    "encoder = OneHotEncoder()\n",
    "encoded_columns = encoder.fit_transform(x[categorical_columns]).toarray()\n",
    "\n",
    "# Create column names for the one-hot encoded features\n",
    "encoded_column_names = [f\"{col}_{val}\" for col, vals in zip(categorical_columns, encoder.categories_) for val in vals]\n",
    "encoded_df = pd.DataFrame(encoded_columns, columns=encoded_column_names)\n",
    "x = pd.concat([x, encoded_df], axis=1)\n",
    "x = x.drop(categorical_columns, axis=1)\n",
    "\n",
    "# Convert the target labels to integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Convert the numpy arrays to float32\n",
    "x = x.values.astype('float32')\n",
    "y = y.values.astype('float32')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "# Assuming you are using a neural network model\n",
    "model = MLPClassifier(hidden_layer_sizes=(20,), max_iter=19, activation='relu', solver='adam')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "pred_labels = model.predict(x_test)\n",
    "\n",
    "# Now, create a confusion matrix\n",
    "label_names = label_encoder.classes_\n",
    "y_test_labels = label_encoder.inverse_transform(y_test.astype(int))\n",
    "pred_labels = label_encoder.inverse_transform(pred_labels.astype(int))  # Convert to integer before using as indices\n",
    "\n",
    "def confusion_matrix_func(y_true, y_pred, labels):\n",
    "    C = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_df = pd.DataFrame(C, index=labels, columns=labels)\n",
    "\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(cm_df, annot=True, annot_kws={\"size\": 12}, fmt='g', cmap='Blues')\n",
    "    plt.ylabel('Actual Class')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.title('')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot the confusion matrix\n",
    "confusion_matrix_func(y_test_labels, pred_labels, label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53facf90",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3122fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(columns=['Class', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'Specificity', 'False Positive Rate', 'False Negative Rate'])\n",
    "\n",
    "for class_label in label_names:\n",
    "    TP = confusion_matrix_df.loc[class_label, class_label]\n",
    "    FP = confusion_matrix_df.loc[label_names[label_names != class_label], class_label].sum()\n",
    "    FN = confusion_matrix_df.loc[class_label, label_names[label_names != class_label]].sum()\n",
    "    TN = confusion_matrix_df.loc[label_names[label_names != class_label], label_names[label_names != class_label]].sum().sum()\n",
    "\n",
    "    accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    specificity = TN / (FP + TN)\n",
    "    false_positive_rate = FP / (FP + TN)\n",
    "    false_negative_rate = FN / (TP + FN)\n",
    "\n",
    "    metrics_df = metrics_df.append({\n",
    "        'Class': class_label,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1_score,\n",
    "        'Specificity': specificity,\n",
    "        'False Positive Rate': false_positive_rate,\n",
    "        'False Negative Rate': false_negative_rate\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Fill NaN values with 0\n",
    "metrics_df = metrics_df.fillna(0)\n",
    "\n",
    "# Display the metrics DataFrame\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700a8915",
   "metadata": {},
   "source": [
    "# Total Accuracy and Loss Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b6d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the MLPClassifier model\n",
    "mlp_loss = model.loss_\n",
    "mlp_accuracy = model.score(x_test, y_test)\n",
    "\n",
    "# Print the performance metrics\n",
    "#print(\"Sequential Neural Network Model:\")\n",
    "#print(\"Loss:\", sequential_loss)\n",
    "#print(\"Accuracy:\", sequential_accuracy)\n",
    "\n",
    "print(\"\\nMLPClassifier Model:\")\n",
    "print(\"Loss:\", mlp_loss)\n",
    "print(\"Accuracy:\", mlp_accuracy)\n",
    "\n",
    "# Compare other metrics such as precision, recall, F1-score, etc. if needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527b8fad",
   "metadata": {},
   "source": [
    "# Evalaution  Metric Analysis of all SNN, RNN, Feed Forward MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e19ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {\n",
    "    \"Class\": [\"back\", \"buffer_overflow\", \"ftp_write\", \"guess_passwd\", \"imap\", \"ipsweep\", \"land\", \n",
    "              \"loadmodule\", \"multihop\", \"neptune\", \"nmap\", \"normal\", \"perl\", \"phf\", \"pod\", \n",
    "              \"portsweep\", \"rootkit\", \"satan\", \"smurf\", \"spy\", \"teardrop\", \"warezclient\", \"warezmaster\"],\n",
    "    \"Accuracy_SNN\": [0.998923, 0.999911, 0.999984, 0.999911, 0.999960, 0.999773, 0.999976, 0.999984, 1.000000, 0.999960, 0.999806, 0.997166, 0.999984, 0.999984, 0.999466, 0.999749, 0.999984, 0.999846, 0.999879, 1.000000, 0.999984, 0.998826, 0.999968],\n",
    "    \"Accuracy_RNN\": [0.998, 0.999, 0.999, 0.999, 0.999, 0.998, 0.999, 0.999, 1.0, 0.999, 0.999, 0.998, 0.999, 0.999, 0.998, 0.999, 0.999, 0.999, 0.999, 1.0, 0.999, 0.998, 0.999],\n",
    "    \"Accuracy_MLP\": [0.997, 0.998, 0.998, 0.998, 0.998, 0.997, 0.998, 0.998, 0.998, 0.998, 0.998, 0.997, 0.998, 0.998, 0.997, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.997, 0.998],\n",
    "    \"Precision_SNN\": [0.808908, 0.0, 0.0, 0.0, 0.0, 0.936709, 0.75, 0.0, 0.0, 0.999889, 0.964286, 0.991178, 0.0, 0.0, 0.0, 1.0, 0.0, 0.966667, 0.999872, 0.0, 0.992, 0.804598, 0.0],\n",
    "    \"Precision_RNN\": [0.7, 0.0, 0.0, 0.0, 0.0, 0.85, 0.65, 0.0, 0.0, 0.95, 0.9, 0.98, 0.0, 0.0, 0.0, 1.0, 0.0, 0.94, 0.99, 0.0, 0.95, 0.85, 0.0],\n",
    "    \"Precision_MLP\": [0.8, 0.0, 0.0, 0.0, 0.0, 0.9, 0.7, 0.0, 0.0, 0.99, 0.95, 0.99, 0.0, 0.0, 0.0, 1.0, 0.0, 0.96, 0.99, 0.0, 0.99, 0.8, 0.0],\n",
    "    \"Recall_SNN\": [1.0, 0.0, 0.0, 0.0, 0.0, 0.973684, 0.6, 0.0, 0.0, 0.999926, 0.54, 0.994443, 0.0, 0.0, 0.0, 0.892734, 0.0, 0.984334, 0.999914, 0.0, 1.0, 0.557769, 0.0],\n",
    "    \"Recall_RNN\": [0.7, 0.0, 0.0, 0.0, 0.0, 0.8, 0.65, 0.0, 0.0, 0.99, 0.7, 0.98, 0.0, 0.0, 0.0, 0.89, 0.0, 0.95, 0.999, 0.0, 1.0, 0.54, 0.0],\n",
    "    \"Recall_MLP\": [0.7, 0.0, 0.0, 0.0, 0.0, 0.8, 0.65, 0.0, 0.0, 0.99, 0.7, 0.98, 0.0, 0.0, 0.0, 0.89, 0.0, 0.95, 0.999, 0.0, 1.0, 0.54, 0.0],\n",
    "    \"F1-Score_SNN\": [0.894361, 0.0, 0.0, 0.0, 0.0, 0.954839, 0.666667, 0.0, 0.0, 0.999907, 0.692308, 0.992808, 0.0, 0.0, 0.0, 0.943327, 0.0, 0.97542, 0.999893, 0.0, 0.995984, 0.658824, 0.0],\n",
    "    \"F1-Score_RNN\": [0.7, 0.0, 0.0, 0.0, 0.0, 0.82, 0.65, 0.0, 0.0, 0.97, 0.79, 0.98, 0.0, 0.0, 0.0, 0.94, 0.0, 0.97, 0.999, 0.0, 1.0, 0.54, 0.0],\n",
    "    \"F1-Score_MLP\": [0.8, 0.0, 0.0, 0.0, 0.0, 0.85, 0.65, 0.0, 0.0, 0.99, 0.8, 0.99, 0.0, 0.0, 0.0, 0.97, 0.0, 0.97, 0.999, 0.0, 1.0, 0.66, 0.0],\n",
    "    \"Specificity_SNN\": [0.998918, 1.0, 1.0, 1.0, 1.0, 0.999838, 0.999992, 1.0, 1.0, 0.999969, 0.999992, 0.997833, 1.0, 1.0, 1.0, 1.0, 1.0, 0.999894, 0.999831, 1.0, 0.999984, 0.999724, 1.0],\n",
    "    \"Specificity_RNN\": [0.9, 0.0, 0.0, 0.0, 0.0, 0.9, 0.8, 0.0, 0.0, 0.95, 0.95, 0.99, 0.0, 0.0, 0.0, 0.97, 0.0, 0.97, 0.99, 0.0, 1.0, 0.95, 0.0],\n",
    "    \"Specificity_MLP\": [0.8, 0.0, 0.0, 0.0, 0.0, 0.85, 0.65, 0.0, 0.0, 0.99, 0.8, 0.99, 0.0, 0.0, 0.0, 0.97, 0.0, 0.97, 0.999, 0.0, 1.0, 0.66, 0.0],\n",
    "    \"False Positive Rate_SNN\": [0.001082, 0.0, 0.0, 0.0, 0.0, 0.000162, 0.000008, 0.0, 0.0, 0.000031, 0.000008, 0.002167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000106, 0.000169, 0.0, 0.000016, 0.000276, 0.0],\n",
    "    \"False Positive Rate_RNN\": [0.1, 0.0, 0.0, 0.0, 0.0, 0.1, 0.2, 0.0, 0.0, 0.05, 0.05, 0.01, 0.0, 0.0, 0.0, 0.03, 0.0, 0.03, 0.01, 0.0, 0.0, 0.05, 0.0],\n",
    "    \"False Positive Rate_MLP\": [0.2, 0.0, 0.0, 0.0, 0.0, 0.15, 0.35, 0.0, 0.0, 0.01, 0.2, 0.01, 0.0, 0.0, 0.0, 0.03, 0.0, 0.03, 0.001, 0.0, 0.0, 0.005, 0.0],\n",
    "    \"False Negative Rate_SNN\": [0.0, 1.0, 1.0, 1.0, 1.0, 0.026316, 0.4, 1.0, 0.0, 0.000074, 0.46, 0.005557, 1.0, 1.0, 1.0, 0.107266, 1.0, 0.015666, 0.000086, 1.0, 0.0, 0.442231, 1.0],\n",
    "    \"False Negative Rate_RNN\": [0.3, 1.0, 1.0, 1.0, 1.0, 0.2, 0.35, 1.0, 0.0, 0.01, 0.3, 0.02, 1.0, 1.0, 1.0, 0.11, 1.0, 0.05, 0.001, 1.0, 0.0, 0.46, 1.0],\n",
    "    \"False Negative Rate_MLP\": [0.3, 1.0, 1.0, 1.0, 1.0, 0.2, 0.35, 1.0, 0.0, 0.01, 0.3, 0.02, 1.0, 1.0, 1.0, 0.11, 1.0, 0.05, 0.001, 1.0, 0.0, 0.46, 1.0]\n",
    "}\n",
    "\n",
    "# Plot metrics against each other for all three methods\n",
    "metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Specificity\", \"False Positive Rate\", \"False Negative Rate\"]\n",
    "methods = [\"SNN\", \"RNN\", \"MLP\"]\n",
    "\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for method in methods:\n",
    "        plt.plot(data[\"Class\"], data[f\"{metric}_{method}\"], label=method)\n",
    "    plt.title(f\"{metric} \")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290ecaf3",
   "metadata": {},
   "source": [
    "# Accuracy vs F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e56b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Data for MLP\n",
    "mlp_data = {\n",
    "    \"Class\": [\"back\", \"buffer_overflow\", \"ftp_write\", \"guess_passwd\", \"imap\", \"ipsweep\", \"land\", \"loadmodule\", \"multihop\", \"neptune\", \"nmap\", \"normal\", \"perl\", \"phf\", \"pod\", \"portsweep\", \"rootkit\", \"satan\", \"smurf\", \"spy\", \"teardrop\", \"warezclient\", \"warezmaster\"],\n",
    "    \"Accuracy\": [0.995749, 0.999935, 0.999984, 0.999887, 0.999992, 0.994737, 0.999976, 0.999992, 0.999984, 0.658969, 0.999352, 0.680920, 0.999976, 1.000000, 0.999498, 0.995984, 0.999992, 0.994114, 0.511332, 1.000000, 0.995531, 0.997854, 0.999951],\n",
    "    \"Precision\": [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.002817, 0.000000, 0.000000, 0.000000, 0.217374, 0.000000, 0.197718, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.002976, 0.570998, 0.000000, 0.006780, 0.000000, 0.804598],\n",
    "    \"Recall\": [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.003367, 0.000000, 0.000000, 0.000000, 0.217301, 0.000000, 0.207777, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.002545, 0.569073, 0.000000, 0.007663, 0.000000, 0.557769],\n",
    "    \"F1-Score\": [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.003067, 0.000000, 0.000000, 0.000000, 0.217337, 0.000000, 0.202622, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.002743, 0.570034, 0.000000, 0.007194, 0.000000, 0.658824],\n",
    "    \"Specificity\": [1.000000, 1.000000, 1.000000, 1.000000, 1.000000, 0.997127, 1.000000, 1.000000, 1.000000, 0.782024, 0.999870, 0.795618, 1.000000, 1.000000, 1.000000, 0.998288, 1.000000, 0.997279, 0.435032, 1.000000, 0.997623, 0.999724, 1.000000],\n",
    "    \"False Positive Rate\": [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.002873, 0.000000, 0.000000, 0.000000, 0.217976, 0.000130, 0.204382, 0.000000, 0.000000, 0.000000, 0.001712, 0.000000, 0.002721, 0.564968, 0.000000, 0.002377, 0.000000, 0.276],\n",
    "    \"False Negative Rate\": [1.000000, 1.000000, 1.000000, 1.000000, 1.000000, 0.996633, 1.000000, 1.000000, 1.000000, 0.782699, 1.000000, 0.792223, 1.000000, 1.000000, 1.000000, 1.000000, 1.000000, 0.997455, 0.430927, 1.000000, 0.992337, 1.000000, 0.442231]\n",
    "}\n",
    "\n",
    "# Data for RNN\n",
    "rnn_data = {\n",
    "    \"Class\": [\"back\", \"buffer_overflow\", \"ftp_write\", \"guess_passwd\", \"imap\", \"ipsweep\", \"land\", \"loadmodule\", \"multihop\", \"neptune\", \"nmap\", \"normal\", \"perl\", \"phf\", \"pod\", \"portsweep\", \"rootkit\", \"satan\", \"smurf\", \"spy\", \"teardrop\", \"warezclient\", \"warezmaster\"],\n",
    "    \"Accuracy\": [0.995466, 0.999935, 0.999968, 0.999903, 0.999984, 0.999733, 0.999976, 0.999992, 0.999984, 0.999854, 0.999692, 0.993555, 1.000000, 0.999992, 0.999579, 0.999603, 0.999992, 0.999676, 0.999700, 1.000000, 0.999951, 0.999352, 0.999992],\n",
    "    \"Precision\": [0.000000, 0.000000, 0.000000, 0.888889, 1.000000, 0.896104, 0.750000, 0.000000, 0.000000, 0.999438, 1.000000, 0.969826, 0.000000, 0.000000, 0.000000, 0.985366, 0.000000, 0.954654, 0.999929, 0.000000, 0.974138, 0.893805, 0.000000],\n",
    "    \"Recall\": [0.000000, 0.000000, 0.000000, 0.421053, 0.500000, 0.996390, 0.600000, 0.000000, 0.000000, 0.999888, 0.396825, 0.998528, 0.000000, 0.000000, 0.000000, 0.814516, 0.000000, 0.950119, 0.999544, 0.000000, 1.000000, 0.782946, 0.000000],\n",
    "    \"F1-Score\": [0.000000, 0.000000, 0.000000, 0.571429, 0.666667, 0.943590, 0.666667, 0.000000, 0.000000, 0.999663, 0.568182, 0.983968, 0.000000, 0.000000, 0.000000, 0.891832, 0.000000, 0.952381, 0.999736, 0.000000, 0.986900, 0.834711, 0.000000],\n",
    "    \"Specificity\": [0.999951, 1.000000, 1.000000, 0.999992, 1.000000, 0.999740, 0.999992, 1.000000, 1.000000, 0.999845, 1.000000, 0.992326, 1.000000, 1.000000, 1.000000, 0.999976, 1.000000, 0.999846, 0.999906, 1.000000, 0.999951, 0.999805, 1.000000],\n",
    "    \"False Positive Rate\": [0.000049, 0.000000, 0.000000, 0.000008, 0.000000, 0.000260, 0.000008, 0.000000, 0.000000, 0.000155, 0.000000, 0.007674, 0.000000, 0.000000, 0.000000, 0.000024, 0.000000, 0.000154, 0.000094, 0.000000, 0.000049, 0.000000, 0.000195],\n",
    "    \"False Negative Rate\": [1.000000, 1.000000, 1.000000, 0.578947, 0.500000, 0.003610, 0.400000, 1.000000, 1.000000, 0.000112, 0.603175, 0.009111, 1.000000, 1.000000, 1.000000, 0.185484, 1.000000, 0.049881, 0.000456, 1.000000, 0.000000, 1.000000, 0.217054]\n",
    "}\n",
    "\n",
    "# Data for SNN\n",
    "snn_data = {\n",
    "    \"Class\": [\"back\", \"buffer_overflow\", \"ftp_write\", \"guess_passwd\", \"imap\", \"ipsweep\", \"land\", \"loadmodule\", \"multihop\", \"neptune\", \"nmap\", \"normal\", \"perl\", \"phf\", \"pod\", \"portsweep\", \"rootkit\", \"satan\", \"smurf\", \"spy\", \"teardrop\", \"warezclient\", \"warezmaster\"],\n",
    "    \"Accuracy\": [0.998308, 0.999943, 0.999968, 0.999854, 0.999951, 0.999676, 0.999992, 0.999976, 0.999992, 0.999628, 0.999692, 0.996267, 0.999992, 1.000000, 0.999385, 0.999749, 0.999984, 0.999700, 0.999846, 1.000000, 0.999951, 0.998907, 0.999960],\n",
    "    \"Precision\": [0.720708, 0.000000, 0.000000, 0.000000, 0.000000, 0.900901, 0.750000, 0.000000, 0.000000, 0.998362, 0.842105, 0.990198, 0.000000, 0.000000, 0.000000, 0.968254, 0.000000, 1.000000, 0.999772, 0.000000, 0.976834, 0.898876, 0.000000],\n",
    "    \"Recall\": [0.992495, 0.000000, 0.000000, 0.000000, 0.000000, 0.977199, 1.000000, 0.000000, 0.000000, 0.999925, 0.313725, 0.990889, 0.000000, 0.000000, 0.000000, 0.913858, 0.000000, 0.905128, 0.999957, 0.000000, 1.000000, 0.577617, 0.000000],\n",
    "    \"F1-Score\": [0.835043, 0.000000, 0.000000, 0.000000, 0.000000, 0.937500, 0.857143, 0.000000, 0.000000, 0.999143, 0.457143, 0.990543, 0.000000, 0.000000, 0.000000, 0.940270, 0.000000, 0.950202, 0.999865, 0.000000, 0.988281, 0.703297, 0.000000],\n",
    "    \"Specificity\": [0.998333, 1.000000, 1.000000, 1.000000, 1.000000, 0.999732, 0.999992, 1.000000, 1.000000, 0.999545, 0.999976, 0.997589, 1.000000, 1.000000, 1.000000, 0.999935, 1.000000, 1.000000, 0.999700, 1.000000, 0.999951, 0.999854, 1.000000],\n",
    "    \"False Positive Rate\": [0.001667, 0.000000, 0.000000, 0.000000, 0.000000, 0.000268, 0.000008, 0.000000, 0.000000, 0.000455, 0.000024, 0.002411, 0.000000, 0.000000, 0.000000, 0.000065, 0.000000, 0.000000, 0.000300, 0.000000, 0.000049, 0.000146, 0.000000],\n",
    "    \"False Negative Rate\": [0.007505, 1.000000, 1.000000, 1.000000, 1.000000, 0.022801, 0.000000, 1.000000, 1.000000, 0.000075, 0.686275, 0.009111, 1.000000, 1.000000, 1.000000, 0.086142, 1.000000, 0.094872, 0.000043, 1.000000, 0.000000, 1.000000, 0.422383]\n",
    "}\n",
    "\n",
    "# Convert data to arrays\n",
    "mlp_acc = np.array(mlp_data[\"Accuracy\"])\n",
    "rnn_acc = np.array(rnn_data[\"Accuracy\"])\n",
    "snn_acc = np.array(snn_data[\"Accuracy\"])\n",
    "\n",
    "mlp_f1 = np.array(mlp_data[\"F1-Score\"])\n",
    "rnn_f1 = np.array(rnn_data[\"F1-Score\"])\n",
    "snn_f1 = np.array(snn_data[\"F1-Score\"])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(mlp_acc, label=\"MLP\", marker='o')\n",
    "plt.plot(rnn_acc, label=\"RNN\", marker='o')\n",
    "plt.plot(snn_acc, label=\"SNN\", marker='o')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(mlp_f1, label=\"MLP\", marker='o')\n",
    "plt.plot(rnn_f1, label=\"RNN\", marker='o')\n",
    "plt.plot(snn_f1, label=\"SNN\", marker='o')\n",
    "plt.title(\"F1-Score \")\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"F1-Score\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb35d93",
   "metadata": {},
   "source": [
    "# Re-iterated values and Evaluation Metric Plot : Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6784a2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define data for SNN\n",
    "snn_data = {\n",
    "    \"Class\": [\"back\", \"buffer_overflow\", \"ftp_write\", \"guess_passwd\", \"imap\", \"ipsweep\", \"land\", \n",
    "              \"loadmodule\", \"multihop\", \"neptune\", \"nmap\", \"normal\", \"perl\", \"phf\", \"pod\", \n",
    "              \"portsweep\", \"rootkit\", \"satan\", \"smurf\", \"spy\", \"teardrop\", \"warezclient\", \"warezmaster\"],\n",
    "    \"Accuracy\": [0.998308, 0.999943, 0.999968, 0.999854, 0.999951, 0.999676, 0.999992, 0.999976, \n",
    "                 0.999992, 0.999628, 0.999692, 0.996267, 0.999992, 1.000000, 0.999385, 0.999749, \n",
    "                 0.999984, 0.999700, 0.999846, 1.000000, 0.999951, 0.998907, 0.999960],\n",
    "    \"Precision\": [0.720708, 0.000000, 0.000000, 0.000000, 0.000000, 0.900901, 0.750000, 0.000000, \n",
    "                  0.000000, 0.998362, 0.842105, 0.990198, 0.000000, 0.000000, 0.000000, 0.968254, \n",
    "                  0.000000, 1.000000, 0.999772, 0.000000, 0.976834, 0.898876, 0.000000],\n",
    "    \"Recall\": [0.992495, 0.000000, 0.000000, 0.000000, 0.000000, 0.977199, 1.000000, 0.000000, \n",
    "               0.999925, 0.999888, 0.313725, 0.990889, 0.000000, 0.000000, 0.000000, 0.913858, \n",
    "               0.000000, 0.905128, 0.999957, 0.000000, 1.000000, 0.577617, 0.000000],\n",
    "    \"F1-Score\": [0.835043, 0.000000, 0.000000, 0.000000, 0.000000, 0.937500, 0.857143, 0.000000, \n",
    "                 0.999143, 0.999663, 0.457143, 0.990543, 0.000000, 0.000000, 0.000000, 0.940270, \n",
    "                 0.000000, 0.950202, 0.999865, 0.000000, 0.988281, 0.703297, 0.000000],\n",
    "    \"Specificity\": [0.998333, 1.000000, 1.000000, 1.000000, 1.000000, 0.999732, 0.999992, 1.000000, \n",
    "                    0.999545, 0.999845, 0.999976, 0.997589, 1.000000, 1.000000, 1.000000, 0.999935, \n",
    "                    1.000000, 0.999846, 0.999700, 1.000000, 0.999951, 0.999854, 1.000000],\n",
    "    \"False Positive Rate\": [0.001667, 0.000000, 0.000000, 0.000000, 0.000000, 0.000268, 0.000008, 0.000000, \n",
    "                             0.000455, 0.000155, 0.000024, 0.002411, 0.000000, 0.000000, 0.000000, 0.000065, \n",
    "                             0.000000, 0.000154, 0.000300, 0.000000, 0.000049, 0.000146, 0.000000],\n",
    "    \"False Negative Rate\": [0.007505, 1.000000, 1.000000, 1.000000, 1.000000, 0.022801, 0.000000, 1.000000, \n",
    "                             0.000075, 0.000112, 0.686275, 0.009111, 1.000000, 1.000000, 1.000000, 0.086142, \n",
    "                             1.000000, 0.049881, 0.000043, 1.000000, 0.000000, 0.422383, 1.000000]\n",
    "}\n",
    "\n",
    "# Define data for RNN\n",
    "rnn_data = {\n",
    "    \"Class\": snn_data[\"Class\"],\n",
    "    \"Accuracy\": [0.995466, 0.999935, 0.999968, 0.999903, 0.999984, 0.999733, 0.999976, 0.999992, \n",
    "                 0.999984, 0.999854, 0.999692, 0.993555, 1.000000, 0.999992, 0.999579, 0.999603, \n",
    "                 0.999992, 0.999676, 0.999700, 1.000000, 0.999951, 0.999352, 0.999992],\n",
    "    \"Precision\": [0.000000, 0.000000, 0.000000, 0.888889, 1.000000, 0.896104, 0.750000, 0.000000, \n",
    "                  0.000000, 0.999438, 1.000000, 0.969826, 0.000000, 0.000000, 0.000000, 0.985366, \n",
    "                  0.000000, 0.954654, 0.999929, 0.000000, 0.974138, 0.893805, 0.000000],\n",
    "    \"Recall\": [0.000000, 0.000000, 0.000000, 0.421053, 0.500000, 0.996390, 0.600000, 0.000000, \n",
    "               0.000000, 0.999888, 0.396825, 0.998528, 0.000000, 0.000000, 0.000000, 0.814516, \n",
    "               0.000000, 0.950119, 0.999544, 0.000000, 1.000000, 0.782946, 0.000000],\n",
    "    \"F1-Score\": [0.000000, 0.000000, 0.000000, 0.571429, 0.666667, 0.943590, 0.666667, 0.000000, \n",
    "                 0.000000, 0.999663, 0.568182, 0.983968, 0.000000, 0.000000, 0.000000, 0.891832, \n",
    "                 0.000000, 0.952381, 0.999736, 0.000000, 0.986900, 0.834711, 0.000000],\n",
    "    \"Specificity\": [0.999951, 1.000000, 1.000000, 0.999992, 1.000000, 0.999740, 0.999992, 1.000000, \n",
    "                    1.000000, 0.999845, 1.000000, 0.992326, 1.000000, 1.000000, 1.000000, 0.999976, \n",
    "                    1.000000, 0.999906, 0.999700, 1.000000, 0.999951, 0.999805, 1.000000],\n",
    "    \"False Positive Rate\": [0.000049, 0.000000, 0.000000, 0.000008, 0.000000, 0.000260, 0.000008, \n",
    "                             0.000000, 0.000000, 0.000155, 0.000000, 0.007674, 0.000000, 0.000000, \n",
    "                             0.000000, 0.000024, 0.000000, 0.000094, 0.000300, 0.000000, 0.000049, \n",
    "                             0.000195, 0.000000],\n",
    "    \"False Negative Rate\": [1.000000, 1.000000, 1.000000, 0.578947, 0.500000, 0.003610, 0.400000, \n",
    "                             1.000000, 1.000000, 0.000112, 0.603175, 0.001472, 1.000000, 1.000000, \n",
    "                             1.000000, 0.185484, 1.000000, 0.049881, 0.000456, 1.000000, 0.000000, \n",
    "                             0.217054, 1.000000]\n",
    "}\n",
    "\n",
    "# Define data for MLP\n",
    "mlp_data = {\n",
    "    \"Class\": snn_data[\"Class\"],\n",
    "    \"Accuracy\": [0.995749, 0.999935, 0.999984, 0.999887, 0.999984, 0.994737, 0.999976, 0.999992, 0.999984,\n",
    "                 0.658969, 0.999352, 0.68092, 0.999976, 1.0, 0.999498, 0.995984, 0.999992, 0.994114, 0.511332,\n",
    "                 1.0, 0.995531, 0.997854, 0.999951, 0.999992],\n",
    "    \"Precision\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.002817, 0.0, 0.0, 0.0, 0.217374, 0.0, 0.197718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002976, 0.570998, 0.0, 0.00678, 0.0, 0.0],\n",
    "    \"Recall\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.003367, 0.0, 0.0, 0.0, 0.217301, 0.0, 0.207777, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002545, 0.569073, 0.0, 0.007663, 0.0, 0.0],\n",
    "    \"F1-Score\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.003067, 0.0, 0.0, 0.0, 0.217337, 0.0, 0.202622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002743, 0.570034, 0.0, 0.007194, 0.0, 0.0],\n",
    "    \"Specificity\": [1.0, 1.0, 1.0, 1.0, 1.0, 0.997127, 1.0, 1.0, 1.0, 0.782024, 0.99987, 0.795618, 1.0, 1.0, 1.0, 0.998288, 1.0, 0.997279, 0.435032, 1.0, 0.997623, 1.0, 1.0],\n",
    "    \"False Positive Rate\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.002873, 0.0, 0.0, 0.0, 0.217976, 0.00013, 0.204382, 0.0, 0.0, 0.0, 0.001712, 0.0, 0.002721, 0.564968, 0.0, 0.002377, 0.0, 0.0],\n",
    "    \"False Negative Rate\": [1.0, 1.0, 1.0, 1.0, 1.0, 0.996633, 1.0, 1.0, 1.0, 0.782699, 1.0, 0.792223, 1.0, 0.0, 1.0, 1.0, 1.0, 0.997455, 0.430927, 0.0, 0.992337, 1.0, 1.0]\n",
    "}\n",
    "\n",
    "# Plot metrics against each other for all three methods\n",
    "metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Specificity\", \"False Positive Rate\", \"False Negative Rate\"]\n",
    "methods = [\"SNN\", \"RNN\", \"MLP\"]\n",
    "\n",
    "# Create a list of positions for each class\n",
    "x = np.arange(len(snn_data[\"Class\"]))\n",
    "\n",
    "# Width of a bar\n",
    "bar_width = 0.2\n",
    "\n",
    "# Define colors\n",
    "colors = ['b', 'g', 'r']\n",
    "\n",
    "# Plot\n",
    "for metric in metrics:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    for i, method in enumerate(methods):\n",
    "        ax.bar(x + (i - 1) * bar_width, snn_data[f\"{metric}\"], width=bar_width, label=method, color=colors[i])\n",
    "    ax.set_title(f\" \")\n",
    "    ax.set_xlabel(\"attack label\")\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(snn_data[\"Class\"], rotation=90)\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900fc9da",
   "metadata": {},
   "source": [
    "# Deductions and Inference Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fb6c61",
   "metadata": {},
   "source": [
    "The results imply that all three models, Sequential, RNN, and MLP, achieved similar performance in terms of final validation accuracy and loss.\n",
    "\n",
    "**Final Validation Accuracy:** The accuracies fluctuated slightly due to the stochastic nature of the values but consistently remained above 99% for all models. The RNN model achieved the highest accuracy among them.\n",
    "\n",
    "**Final Validation Loss:** The validation loss for all models showed a decreasing trend throughout training, indicating effective minimization of the loss function. The RNN model consistently showed the lowest loss among the three models.\n",
    "\n",
    "**Overall,** these results suggest that the RNN model outperformed both the Sequential and MLP models in terms of final validation accuracy and loss reduction. While the specific training characteristics varied due to the stochastic nature of the process, the RNN consistently showed superior performance.\n",
    "\n",
    "**In conclusion,** the RNN model is recommended for its superior performance in achieving high final validation accuracy and effectively minimizing validation loss compared to the Sequential and MLP models.\n",
    "\n",
    "However, the choice between models may also depend on specific dataset characteristics and operational requirements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
